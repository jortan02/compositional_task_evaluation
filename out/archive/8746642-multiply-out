mkdir: cannot create directory ‘/scratch/general/vast/u1283221/huggingface_cache’: File exists
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:51<03:24, 51.09s/it]Loading checkpoint shards:  40%|████      | 2/5 [01:40<02:30, 50.23s/it]Loading checkpoint shards:  60%|██████    | 3/5 [02:35<01:44, 52.14s/it]Loading checkpoint shards:  80%|████████  | 4/5 [03:27<00:52, 52.07s/it]Loading checkpoint shards: 100%|██████████| 5/5 [03:40<00:00, 38.06s/it]Loading checkpoint shards: 100%|██████████| 5/5 [03:40<00:00, 44.06s/it]
>> Input file: ./data/multiplication/instruction_type-1/prompt_type-1/multiply-primed-4.csv, Output file: ./results/multiplication/instruction_type-1/prompt_type-1/multiply-primed-4/google/flan-t5-xxl/experiment-5.csv, Module: google/flan-t5-xxl, Batch size: 20
<class 'datasets.arrow_dataset.Dataset'>
  0%|          | 0/3250 [00:00<?, ?it/s]  0%|          | 1/3250 [00:27<25:06:40, 27.82s/it]  0%|          | 2/3250 [00:30<11:56:08, 13.23s/it]  0%|          | 3/3250 [00:34<7:48:26,  8.66s/it]   0%|          | 4/3250 [00:37<5:48:39,  6.44s/it]  0%|          | 5/3250 [00:40<4:43:15,  5.24s/it]  0%|          | 6/3250 [00:43<4:03:30,  4.50s/it]  0%|          | 7/3250 [00:46<3:38:49,  4.05s/it]  0%|          | 8/3250 [00:49<3:21:42,  3.73s/it]  0%|          | 9/3250 [00:52<3:12:08,  3.56s/it]  0%|          | 10/3250 [00:55<3:03:08,  3.39s/it]  0%|          | 11/3250 [00:58<2:57:36,  3.29s/it]  0%|          | 12/3250 [01:01<2:54:00,  3.22s/it]  0%|          | 13/3250 [01:04<2:53:55,  3.22s/it]  0%|          | 14/3250 [01:07<2:49:45,  3.15s/it]  0%|          | 15/3250 [01:11<2:48:00,  3.12s/it]  0%|          | 16/3250 [01:14<2:46:13,  3.08s/it]  1%|          | 17/3250 [01:17<2:45:23,  3.07s/it]  1%|          | 18/3250 [01:20<2:48:28,  3.13s/it]  1%|          | 19/3250 [01:23<2:46:48,  3.10s/it]  1%|          | 20/3250 [01:26<2:45:52,  3.08s/it]  1%|          | 21/3250 [01:29<2:44:34,  3.06s/it]  1%|          | 22/3250 [01:32<2:44:59,  3.07s/it]  1%|          | 23/3250 [01:35<2:44:48,  3.06s/it]  1%|          | 24/3250 [01:38<2:47:36,  3.12s/it]  1%|          | 25/3250 [01:42<2:54:00,  3.24s/it]  1%|          | 26/3250 [01:45<2:50:24,  3.17s/it]  1%|          | 27/3250 [01:48<2:47:35,  3.12s/it]  1%|          | 28/3250 [01:51<2:45:30,  3.08s/it]  1%|          | 29/3250 [01:54<2:46:30,  3.10s/it]  1%|          | 30/3250 [01:57<2:46:26,  3.10s/it]  1%|          | 31/3250 [02:00<2:45:18,  3.08s/it]  1%|          | 32/3250 [02:03<2:47:15,  3.12s/it]  1%|          | 33/3250 [02:06<2:45:38,  3.09s/it]  1%|          | 34/3250 [02:09<2:42:51,  3.04s/it]  1%|          | 35/3250 [02:13<2:50:45,  3.19s/it]  1%|          | 36/3250 [02:16<2:52:20,  3.22s/it]  1%|          | 37/3250 [02:19<2:49:24,  3.16s/it]  1%|          | 38/3250 [02:23<2:59:05,  3.35s/it]  1%|          | 39/3250 [02:27<3:03:47,  3.43s/it]  1%|          | 40/3250 [02:30<3:10:22,  3.56s/it]  1%|▏         | 41/3250 [02:33<3:02:52,  3.42s/it]  1%|▏         | 42/3250 [02:37<2:57:04,  3.31s/it]  1%|▏         | 43/3250 [02:40<2:53:25,  3.24s/it]  1%|▏         | 44/3250 [02:43<2:57:58,  3.33s/it]  1%|▏         | 45/3250 [02:47<3:02:20,  3.41s/it]  1%|▏         | 46/3250 [02:50<2:57:08,  3.32s/it]  1%|▏         | 47/3250 [02:53<2:52:36,  3.23s/it]  1%|▏         | 48/3250 [02:56<2:54:03,  3.26s/it]  2%|▏         | 49/3250 [03:00<2:59:21,  3.36s/it]  2%|▏         | 50/3250 [03:03<3:03:38,  3.44s/it]  2%|▏         | 51/3250 [03:07<3:00:29,  3.39s/it]  2%|▏         | 52/3250 [03:12<3:35:23,  4.04s/it]  2%|▏         | 53/3250 [03:15<3:19:09,  3.74s/it]  2%|▏         | 54/3250 [03:19<3:16:39,  3.69s/it]  2%|▏         | 55/3250 [03:22<3:15:13,  3.67s/it]  2%|▏         | 56/3250 [03:25<3:03:59,  3.46s/it]  2%|▏         | 57/3250 [03:28<2:57:26,  3.33s/it]  2%|▏         | 58/3250 [03:32<3:04:48,  3.47s/it]  2%|▏         | 59/3250 [03:36<3:05:53,  3.50s/it]  2%|▏         | 60/3250 [03:40<3:08:36,  3.55s/it]  2%|▏         | 61/3250 [03:42<2:59:44,  3.38s/it]  2%|▏         | 62/3250 [03:46<2:53:53,  3.27s/it]  2%|▏         | 63/3250 [03:49<3:00:20,  3.40s/it]  2%|▏         | 64/3250 [03:54<3:30:20,  3.96s/it]  2%|▏         | 65/3250 [03:58<3:25:28,  3.87s/it]  2%|▏         | 66/3250 [04:01<3:12:46,  3.63s/it]  2%|▏         | 67/3250 [04:05<3:10:41,  3.59s/it]  2%|▏         | 68/3250 [04:10<3:34:04,  4.04s/it]  2%|▏         | 69/3250 [04:14<3:28:57,  3.94s/it]  2%|▏         | 70/3250 [04:17<3:25:05,  3.87s/it]  2%|▏         | 71/3250 [04:20<3:12:00,  3.62s/it]  2%|▏         | 72/3250 [04:24<3:12:22,  3.63s/it]  2%|▏         | 73/3250 [04:27<3:11:30,  3.62s/it]  2%|▏         | 74/3250 [04:31<3:14:12,  3.67s/it]  2%|▏         | 75/3250 [04:35<3:12:23,  3.64s/it]  2%|▏         | 76/3250 [04:38<3:03:21,  3.47s/it]  2%|▏         | 77/3250 [04:41<2:56:21,  3.33s/it]  2%|▏         | 78/3250 [04:45<3:00:14,  3.41s/it]  2%|▏         | 79/3250 [04:48<3:06:19,  3.53s/it]  2%|▏         | 80/3250 [04:52<3:11:13,  3.62s/it]  2%|▏         | 81/3250 [04:55<3:03:25,  3.47s/it]  3%|▎         | 82/3250 [04:59<3:03:59,  3.48s/it]  3%|▎         | 83/3250 [05:02<3:05:01,  3.51s/it]  3%|▎         | 84/3250 [05:06<3:07:43,  3.56s/it]  3%|▎         | 85/3250 [05:10<3:15:50,  3.71s/it]  3%|▎         | 86/3250 [05:13<3:04:07,  3.49s/it]  3%|▎         | 87/3250 [05:17<3:07:35,  3.56s/it]  3%|▎         | 88/3250 [05:21<3:10:35,  3.62s/it]  3%|▎         | 89/3250 [05:26<3:32:09,  4.03s/it]  3%|▎         | 90/3250 [05:29<3:26:08,  3.91s/it]  3%|▎         | 91/3250 [05:33<3:17:51,  3.76s/it]  3%|▎         | 92/3250 [05:36<3:18:58,  3.78s/it]  3%|▎         | 93/3250 [05:41<3:37:31,  4.13s/it]  3%|▎         | 94/3250 [05:45<3:29:35,  3.98s/it]  3%|▎         | 95/3250 [05:49<3:22:45,  3.86s/it]  3%|▎         | 96/3250 [05:52<3:16:52,  3.75s/it]  3%|▎         | 97/3250 [05:56<3:13:43,  3.69s/it]  3%|▎         | 98/3250 [06:00<3:17:21,  3.76s/it]  3%|▎         | 99/3250 [06:03<3:15:02,  3.71s/it]  3%|▎         | 100/3250 [06:07<3:17:05,  3.75s/it]  3%|▎         | 101/3250 [06:10<3:05:07,  3.53s/it]  3%|▎         | 102/3250 [06:13<3:01:47,  3.46s/it]  3%|▎         | 103/3250 [06:17<3:04:15,  3.51s/it]  3%|▎         | 104/3250 [06:21<3:05:56,  3.55s/it]  3%|▎         | 105/3250 [06:24<3:05:26,  3.54s/it]  3%|▎         | 106/3250 [06:27<2:59:17,  3.42s/it]  3%|▎         | 107/3250 [06:31<3:09:20,  3.61s/it]  3%|▎         | 108/3250 [06:35<3:09:48,  3.62s/it]  3%|▎         | 109/3250 [06:39<3:09:53,  3.63s/it]  3%|▎         | 110/3250 [06:43<3:15:22,  3.73s/it]  3%|▎         | 111/3250 [06:45<3:02:52,  3.50s/it]  3%|▎         | 112/3250 [06:49<3:03:19,  3.51s/it]  3%|▎         | 113/3250 [06:53<3:03:24,  3.51s/it]  4%|▎         | 114/3250 [06:56<3:07:02,  3.58s/it]  4%|▎         | 115/3250 [06:59<2:58:57,  3.42s/it]  4%|▎         | 116/3250 [07:02<2:52:50,  3.31s/it]  4%|▎         | 117/3250 [07:06<2:55:40,  3.36s/it]  4%|▎         | 117/3250 [07:13<3:13:23,  3.70s/it]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/./scripts/t5_cte.py", line 18, in <module>
    experiment.run_experiment(model, tokenizer, batch_size, input_file_path, output_file_path)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/scripts/experiment.py", line 54, in run_experiment
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/scripts/experiment.py", line 41, in _evaluate_model
    generated_texts = _generate_texts(model, tokenizer, encodings)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/scripts/experiment.py", line 31, in _generate_texts
    generated_ids = model.generate(**encodings, max_new_tokens=20, num_beams=5, do_sample=True)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/generation/utils.py", line 1712, in generate
    return self.beam_sample(
           ^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/generation/utils.py", line 3338, in beam_sample
    outputs = self(
              ^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py", line 1774, in forward
    lm_logits = self.lm_head(sequence_output)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/accelerate/hooks.py", line 160, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/accelerate/hooks.py", line 286, in pre_forward
    set_module_tensor_to_device(
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 313, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 502.00 MiB (GPU 0; 44.55 GiB total capacity; 43.29 GiB already allocated; 462.25 MiB free; 43.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
