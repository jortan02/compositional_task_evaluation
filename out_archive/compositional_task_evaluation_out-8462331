mkdir: cannot create directory ‘/scratch/general/vast/u1283221/huggingface_cache’: File exists
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]
Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.45G [00:00<?, ?B/s][A
Downloading (…)l-00001-of-00002.bin:   0%|          | 10.5M/9.45G [00:00<02:03, 76.2MB/s][A
Downloading (…)l-00001-of-00002.bin:   0%|          | 21.0M/9.45G [00:00<02:26, 64.3MB/s][A
Downloading (…)l-00001-of-00002.bin:   0%|          | 31.5M/9.45G [00:00<02:18, 67.9MB/s][A
Downloading (…)l-00001-of-00002.bin:   0%|          | 41.9M/9.45G [00:00<02:18, 68.1MB/s][A
Downloading (…)l-00001-of-00002.bin:   1%|          | 52.4M/9.45G [00:00<02:14, 69.9MB/s][A
Downloading (…)l-00001-of-00002.bin:   1%|          | 62.9M/9.45G [00:00<02:05, 75.0MB/s][A
Downloading (…)l-00001-of-00002.bin:   1%|          | 73.4M/9.45G [00:01<02:11, 71.2MB/s][A
Downloading (…)l-00001-of-00002.bin:   1%|          | 83.9M/9.45G [00:01<02:01, 77.2MB/s][A
Downloading (…)l-00001-of-00002.bin:   1%|          | 94.4M/9.45G [00:01<01:57, 79.7MB/s][A
Downloading (…)l-00001-of-00002.bin:   1%|          | 105M/9.45G [00:01<02:06, 73.8MB/s] [A
Downloading (…)l-00001-of-00002.bin:   1%|          | 115M/9.45G [00:01<02:28, 63.0MB/s][A
Downloading (…)l-00001-of-00002.bin:   1%|▏         | 126M/9.45G [00:01<02:27, 63.4MB/s][A
Downloading (…)l-00001-of-00002.bin:   1%|▏         | 136M/9.45G [00:01<02:12, 70.1MB/s][A
Downloading (…)l-00001-of-00002.bin:   2%|▏         | 147M/9.45G [00:02<02:03, 75.3MB/s][A
Downloading (…)l-00001-of-00002.bin:   2%|▏         | 157M/9.45G [00:02<01:56, 80.0MB/s][A
Downloading (…)l-00001-of-00002.bin:   2%|▏         | 168M/9.45G [00:02<01:57, 79.2MB/s][A
Downloading (…)l-00001-of-00002.bin:   2%|▏         | 178M/9.45G [00:02<01:53, 81.6MB/s][A
Downloading (…)l-00001-of-00002.bin:   2%|▏         | 189M/9.45G [00:02<01:49, 84.3MB/s][A
Downloading (…)l-00001-of-00002.bin:   2%|▏         | 199M/9.45G [00:02<02:09, 71.6MB/s][A
Downloading (…)l-00001-of-00002.bin:   2%|▏         | 210M/9.45G [00:02<02:08, 72.1MB/s][A
Downloading (…)l-00001-of-00002.bin:   2%|▏         | 220M/9.45G [00:03<02:02, 75.4MB/s][A
Downloading (…)l-00001-of-00002.bin:   2%|▏         | 231M/9.45G [00:03<02:10, 70.9MB/s][A
Downloading (…)l-00001-of-00002.bin:   3%|▎         | 241M/9.45G [00:03<02:05, 73.3MB/s][A
Downloading (…)l-00001-of-00002.bin:   3%|▎         | 252M/9.45G [00:03<01:58, 77.4MB/s][A
Downloading (…)l-00001-of-00002.bin:   3%|▎         | 262M/9.45G [00:03<01:53, 81.3MB/s][A
Downloading (…)l-00001-of-00002.bin:   3%|▎         | 273M/9.45G [00:03<01:52, 81.6MB/s][A
Downloading (…)l-00001-of-00002.bin:   3%|▎         | 283M/9.45G [00:03<01:58, 77.3MB/s][A
Downloading (…)l-00001-of-00002.bin:   3%|▎         | 294M/9.45G [00:03<01:57, 78.1MB/s][A
Downloading (…)l-00001-of-00002.bin:   3%|▎         | 304M/9.45G [00:04<02:00, 75.9MB/s][A
Downloading (…)l-00001-of-00002.bin:   3%|▎         | 315M/9.45G [00:04<01:58, 76.9MB/s][A
Downloading (…)l-00001-of-00002.bin:   3%|▎         | 325M/9.45G [00:04<01:56, 78.3MB/s][A
Downloading (…)l-00001-of-00002.bin:   4%|▎         | 336M/9.45G [00:04<01:52, 80.8MB/s][A
Downloading (…)l-00001-of-00002.bin:   4%|▎         | 346M/9.45G [00:04<01:51, 81.6MB/s][A
Downloading (…)l-00001-of-00002.bin:   4%|▍         | 357M/9.45G [00:04<01:51, 81.6MB/s][A
Downloading (…)l-00001-of-00002.bin:   4%|▍         | 367M/9.45G [00:04<02:03, 73.8MB/s][A
Downloading (…)l-00001-of-00002.bin:   4%|▍         | 377M/9.45G [00:05<01:59, 76.2MB/s][A
Downloading (…)l-00001-of-00002.bin:   4%|▍         | 388M/9.45G [00:05<01:54, 79.3MB/s][A
Downloading (…)l-00001-of-00002.bin:   4%|▍         | 398M/9.45G [00:05<01:50, 82.1MB/s][A
Downloading (…)l-00001-of-00002.bin:   4%|▍         | 409M/9.45G [00:05<01:47, 83.8MB/s][A
Downloading (…)l-00001-of-00002.bin:   4%|▍         | 419M/9.45G [00:05<01:46, 85.0MB/s][A
Downloading (…)l-00001-of-00002.bin:   5%|▍         | 430M/9.45G [00:05<01:53, 79.8MB/s][A
Downloading (…)l-00001-of-00002.bin:   5%|▍         | 440M/9.45G [00:05<01:51, 80.9MB/s][A
Downloading (…)l-00001-of-00002.bin:   5%|▍         | 451M/9.45G [00:05<01:48, 82.8MB/s][A
Downloading (…)l-00001-of-00002.bin:   5%|▍         | 461M/9.45G [00:06<01:45, 84.9MB/s][A
Downloading (…)l-00001-of-00002.bin:   5%|▍         | 472M/9.45G [00:06<01:56, 77.3MB/s][A
Downloading (…)l-00001-of-00002.bin:   5%|▌         | 482M/9.45G [00:06<01:54, 78.1MB/s][A
Downloading (…)l-00001-of-00002.bin:   5%|▌         | 493M/9.45G [00:06<01:54, 78.5MB/s][A
Downloading (…)l-00001-of-00002.bin:   5%|▌         | 503M/9.45G [00:06<01:58, 75.2MB/s][A
Downloading (…)l-00001-of-00002.bin:   5%|▌         | 514M/9.45G [00:06<01:55, 77.2MB/s][A
Downloading (…)l-00001-of-00002.bin:   6%|▌         | 524M/9.45G [00:06<01:51, 80.3MB/s][A
Downloading (…)l-00001-of-00002.bin:   6%|▌         | 535M/9.45G [00:07<02:01, 73.4MB/s][A
Downloading (…)l-00001-of-00002.bin:   6%|▌         | 545M/9.45G [00:07<02:03, 72.1MB/s][A
Downloading (…)l-00001-of-00002.bin:   6%|▌         | 556M/9.45G [00:07<01:57, 75.4MB/s][A
Downloading (…)l-00001-of-00002.bin:   6%|▌         | 566M/9.45G [00:07<01:51, 79.7MB/s][A
Downloading (…)l-00001-of-00002.bin:   6%|▌         | 577M/9.45G [00:07<01:52, 78.7MB/s][A
Downloading (…)l-00001-of-00002.bin:   6%|▌         | 587M/9.45G [00:07<01:49, 81.2MB/s][A
Downloading (…)l-00001-of-00002.bin:   6%|▋         | 598M/9.45G [00:07<01:54, 77.1MB/s][A
Downloading (…)l-00001-of-00002.bin:   6%|▋         | 608M/9.45G [00:07<02:03, 71.8MB/s][A
Downloading (…)l-00001-of-00002.bin:   7%|▋         | 619M/9.45G [00:08<02:03, 71.5MB/s][A
Downloading (…)l-00001-of-00002.bin:   7%|▋         | 629M/9.45G [00:08<01:58, 74.8MB/s][A
Downloading (…)l-00001-of-00002.bin:   7%|▋         | 640M/9.45G [00:08<01:51, 78.7MB/s][A
Downloading (…)l-00001-of-00002.bin:   7%|▋         | 650M/9.45G [00:08<01:48, 80.9MB/s][A
Downloading (…)l-00001-of-00002.bin:   7%|▋         | 661M/9.45G [00:08<01:45, 83.2MB/s][A
Downloading (…)l-00001-of-00002.bin:   7%|▋         | 671M/9.45G [00:08<01:43, 84.6MB/s][A
Downloading (…)l-00001-of-00002.bin:   7%|▋         | 682M/9.45G [00:08<01:43, 85.1MB/s][A
Downloading (…)l-00001-of-00002.bin:   7%|▋         | 692M/9.45G [00:08<01:48, 81.0MB/s][A
Downloading (…)l-00001-of-00002.bin:   7%|▋         | 703M/9.45G [00:09<01:49, 79.7MB/s][A
Downloading (…)l-00001-of-00002.bin:   8%|▊         | 713M/9.45G [00:09<01:47, 81.0MB/s][A
Downloading (…)l-00001-of-00002.bin:   8%|▊         | 724M/9.45G [00:09<01:57, 74.1MB/s][A
Downloading (…)l-00001-of-00002.bin:   8%|▊         | 734M/9.45G [00:09<01:54, 76.2MB/s][A
Downloading (…)l-00001-of-00002.bin:   8%|▊         | 744M/9.45G [00:09<02:16, 63.9MB/s][A
Downloading (…)l-00001-of-00002.bin:   8%|▊         | 755M/9.45G [00:09<02:17, 63.2MB/s][A
Downloading (…)l-00001-of-00002.bin:   8%|▊         | 765M/9.45G [00:10<02:50, 51.0MB/s][A
Downloading (…)l-00001-of-00002.bin:   8%|▊         | 786M/9.45G [00:10<02:14, 64.4MB/s][A
Downloading (…)l-00001-of-00002.bin:   8%|▊         | 797M/9.45G [00:10<02:06, 68.5MB/s][A
Downloading (…)l-00001-of-00002.bin:   9%|▊         | 807M/9.45G [00:10<02:02, 70.3MB/s][A
Downloading (…)l-00001-of-00002.bin:   9%|▊         | 818M/9.45G [00:10<01:55, 74.6MB/s][A
Downloading (…)l-00001-of-00002.bin:   9%|▉         | 828M/9.45G [00:10<01:53, 75.7MB/s][A
Downloading (…)l-00001-of-00002.bin:   9%|▉         | 839M/9.45G [00:11<01:57, 73.0MB/s][A
Downloading (…)l-00001-of-00002.bin:   9%|▉         | 849M/9.45G [00:11<01:54, 75.3MB/s][A
Downloading (…)l-00001-of-00002.bin:   9%|▉         | 860M/9.45G [00:11<01:48, 79.3MB/s][A
Downloading (…)l-00001-of-00002.bin:   9%|▉         | 870M/9.45G [00:11<01:43, 82.8MB/s][A
Downloading (…)l-00001-of-00002.bin:   9%|▉         | 881M/9.45G [00:11<01:46, 80.2MB/s][A
Downloading (…)l-00001-of-00002.bin:   9%|▉         | 891M/9.45G [00:11<01:44, 82.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  10%|▉         | 902M/9.45G [00:11<01:44, 81.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  10%|▉         | 912M/9.45G [00:12<02:10, 65.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  10%|▉         | 923M/9.45G [00:12<02:16, 62.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  10%|▉         | 933M/9.45G [00:12<02:05, 67.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  10%|▉         | 944M/9.45G [00:12<01:54, 74.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  10%|█         | 954M/9.45G [00:12<01:53, 74.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  10%|█         | 965M/9.45G [00:12<01:49, 77.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  10%|█         | 975M/9.45G [00:12<01:52, 75.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  10%|█         | 986M/9.45G [00:13<01:52, 75.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  11%|█         | 996M/9.45G [00:13<01:54, 73.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  11%|█         | 1.01G/9.45G [00:13<01:51, 75.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  11%|█         | 1.02G/9.45G [00:13<01:59, 70.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  11%|█         | 1.03G/9.45G [00:13<01:55, 73.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  11%|█         | 1.04G/9.45G [00:13<02:11, 64.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  11%|█         | 1.05G/9.45G [00:14<02:18, 60.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  11%|█         | 1.06G/9.45G [00:14<02:15, 61.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  11%|█▏        | 1.07G/9.45G [00:14<02:04, 67.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  11%|█▏        | 1.08G/9.45G [00:14<02:03, 67.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  12%|█▏        | 1.09G/9.45G [00:14<02:03, 67.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  12%|█▏        | 1.10G/9.45G [00:14<01:57, 70.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  12%|█▏        | 1.11G/9.45G [00:14<01:54, 72.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  12%|█▏        | 1.12G/9.45G [00:15<02:02, 67.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  12%|█▏        | 1.13G/9.45G [00:15<02:10, 63.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  12%|█▏        | 1.14G/9.45G [00:15<01:59, 69.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  12%|█▏        | 1.15G/9.45G [00:15<01:56, 71.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  12%|█▏        | 1.16G/9.45G [00:15<01:53, 73.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  12%|█▏        | 1.17G/9.45G [00:15<01:51, 74.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  13%|█▎        | 1.18G/9.45G [00:16<01:57, 70.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  13%|█▎        | 1.20G/9.45G [00:16<01:59, 68.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  13%|█▎        | 1.21G/9.45G [00:16<01:54, 71.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  13%|█▎        | 1.22G/9.45G [00:16<01:50, 74.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  13%|█▎        | 1.23G/9.45G [00:16<01:49, 75.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  13%|█▎        | 1.24G/9.45G [00:16<01:59, 68.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  13%|█▎        | 1.25G/9.45G [00:16<02:05, 65.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  13%|█▎        | 1.26G/9.45G [00:17<01:57, 70.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  13%|█▎        | 1.27G/9.45G [00:17<01:52, 73.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  14%|█▎        | 1.28G/9.45G [00:17<01:49, 74.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  14%|█▎        | 1.29G/9.45G [00:17<01:47, 76.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  14%|█▍        | 1.30G/9.45G [00:17<01:53, 72.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  14%|█▍        | 1.31G/9.45G [00:17<01:47, 75.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  14%|█▍        | 1.32G/9.45G [00:17<01:49, 74.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  14%|█▍        | 1.33G/9.45G [00:17<01:45, 77.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  14%|█▍        | 1.34G/9.45G [00:18<02:10, 62.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  14%|█▍        | 1.35G/9.45G [00:18<01:59, 67.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  14%|█▍        | 1.36G/9.45G [00:18<01:53, 71.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  15%|█▍        | 1.37G/9.45G [00:18<02:00, 66.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  15%|█▍        | 1.38G/9.45G [00:18<01:55, 69.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  15%|█▍        | 1.39G/9.45G [00:18<01:54, 70.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  15%|█▍        | 1.41G/9.45G [00:19<01:49, 73.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  15%|█▍        | 1.42G/9.45G [00:19<01:45, 76.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  15%|█▌        | 1.43G/9.45G [00:19<01:43, 77.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  15%|█▌        | 1.44G/9.45G [00:19<01:50, 72.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  15%|█▌        | 1.45G/9.45G [00:19<01:55, 69.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  15%|█▌        | 1.46G/9.45G [00:19<02:02, 65.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  16%|█▌        | 1.47G/9.45G [00:19<01:54, 70.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  16%|█▌        | 1.48G/9.45G [00:20<01:50, 72.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  16%|█▌        | 1.49G/9.45G [00:20<01:56, 68.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  16%|█▌        | 1.50G/9.45G [00:20<01:55, 68.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  16%|█▌        | 1.51G/9.45G [00:20<02:16, 58.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  16%|█▌        | 1.52G/9.45G [00:20<02:24, 55.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  16%|█▌        | 1.53G/9.45G [00:21<02:15, 58.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  16%|█▋        | 1.54G/9.45G [00:21<02:01, 65.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  16%|█▋        | 1.55G/9.45G [00:21<01:54, 69.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  17%|█▋        | 1.56G/9.45G [00:21<02:02, 64.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  17%|█▋        | 1.57G/9.45G [00:21<02:17, 57.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  17%|█▋        | 1.58G/9.45G [00:21<02:10, 60.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  17%|█▋        | 1.59G/9.45G [00:22<02:05, 62.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  17%|█▋        | 1.60G/9.45G [00:22<01:55, 67.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  17%|█▋        | 1.61G/9.45G [00:22<01:53, 69.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  17%|█▋        | 1.63G/9.45G [00:22<01:46, 73.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  17%|█▋        | 1.64G/9.45G [00:22<01:47, 72.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  17%|█▋        | 1.65G/9.45G [00:22<01:46, 73.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  18%|█▊        | 1.66G/9.45G [00:22<01:48, 72.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  18%|█▊        | 1.67G/9.45G [00:22<01:43, 75.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  18%|█▊        | 1.68G/9.45G [00:23<01:40, 77.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  18%|█▊        | 1.69G/9.45G [00:23<01:49, 70.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  18%|█▊        | 1.70G/9.45G [00:23<01:42, 75.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  18%|█▊        | 1.71G/9.45G [00:23<01:39, 77.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  18%|█▊        | 1.72G/9.45G [00:23<01:40, 77.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  18%|█▊        | 1.73G/9.45G [00:23<01:44, 74.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  18%|█▊        | 1.74G/9.45G [00:23<01:38, 78.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  19%|█▊        | 1.75G/9.45G [00:24<01:34, 81.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  19%|█▊        | 1.76G/9.45G [00:24<01:36, 80.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  19%|█▉        | 1.77G/9.45G [00:24<01:46, 72.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  19%|█▉        | 1.78G/9.45G [00:24<01:42, 75.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  19%|█▉        | 1.79G/9.45G [00:24<01:47, 71.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  19%|█▉        | 1.80G/9.45G [00:24<01:52, 67.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  19%|█▉        | 1.81G/9.45G [00:24<01:45, 72.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  19%|█▉        | 1.82G/9.45G [00:25<01:40, 76.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  19%|█▉        | 1.84G/9.45G [00:25<01:49, 69.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  20%|█▉        | 1.85G/9.45G [00:25<01:45, 71.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  20%|█▉        | 1.86G/9.45G [00:25<02:03, 61.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  20%|█▉        | 1.87G/9.45G [00:25<01:56, 65.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  20%|█▉        | 1.88G/9.45G [00:25<01:50, 68.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  20%|█▉        | 1.89G/9.45G [00:26<01:48, 69.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  20%|██        | 1.90G/9.45G [00:26<01:40, 75.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  20%|██        | 1.91G/9.45G [00:26<01:38, 76.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  20%|██        | 1.92G/9.45G [00:26<01:39, 76.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  20%|██        | 1.93G/9.45G [00:26<01:39, 75.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  21%|██        | 1.94G/9.45G [00:26<01:41, 73.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  21%|██        | 1.95G/9.45G [00:26<01:52, 66.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  21%|██        | 1.96G/9.45G [00:27<01:52, 66.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  21%|██        | 1.97G/9.45G [00:27<01:43, 72.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  21%|██        | 1.98G/9.45G [00:27<01:40, 74.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  21%|██        | 1.99G/9.45G [00:27<01:37, 76.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  21%|██        | 2.00G/9.45G [00:27<01:37, 76.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  21%|██▏       | 2.01G/9.45G [00:27<01:35, 77.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  21%|██▏       | 2.02G/9.45G [00:27<01:33, 79.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  22%|██▏       | 2.03G/9.45G [00:27<01:29, 82.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  22%|██▏       | 2.04G/9.45G [00:28<01:29, 82.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  22%|██▏       | 2.06G/9.45G [00:28<01:37, 75.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  22%|██▏       | 2.07G/9.45G [00:28<01:37, 75.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  22%|██▏       | 2.08G/9.45G [00:28<01:40, 73.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  22%|██▏       | 2.09G/9.45G [00:28<01:36, 76.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  22%|██▏       | 2.10G/9.45G [00:28<01:34, 77.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  22%|██▏       | 2.11G/9.45G [00:28<01:33, 78.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  22%|██▏       | 2.12G/9.45G [00:29<01:50, 66.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  23%|██▎       | 2.13G/9.45G [00:29<01:41, 72.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  23%|██▎       | 2.14G/9.45G [00:29<01:38, 74.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  23%|██▎       | 2.15G/9.45G [00:29<01:47, 68.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  23%|██▎       | 2.16G/9.45G [00:29<01:50, 65.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  23%|██▎       | 2.17G/9.45G [00:29<01:41, 71.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  23%|██▎       | 2.18G/9.45G [00:29<01:43, 70.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  23%|██▎       | 2.19G/9.45G [00:30<01:45, 69.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  23%|██▎       | 2.20G/9.45G [00:30<01:37, 74.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  23%|██▎       | 2.21G/9.45G [00:30<01:32, 77.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  24%|██▎       | 2.22G/9.45G [00:30<01:39, 72.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  24%|██▎       | 2.23G/9.45G [00:30<02:11, 55.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  24%|██▍       | 2.25G/9.45G [00:31<01:39, 72.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  24%|██▍       | 2.26G/9.45G [00:31<01:44, 68.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  24%|██▍       | 2.28G/9.45G [00:31<01:37, 73.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  24%|██▍       | 2.29G/9.45G [00:31<01:46, 67.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  24%|██▍       | 2.30G/9.45G [00:31<01:37, 73.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  24%|██▍       | 2.31G/9.45G [00:31<01:32, 77.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  25%|██▍       | 2.32G/9.45G [00:31<01:30, 78.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  25%|██▍       | 2.33G/9.45G [00:31<01:28, 80.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  25%|██▍       | 2.34G/9.45G [00:32<01:26, 82.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  25%|██▍       | 2.35G/9.45G [00:32<01:28, 80.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  25%|██▍       | 2.36G/9.45G [00:32<01:30, 78.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  25%|██▌       | 2.37G/9.45G [00:32<01:43, 68.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  25%|██▌       | 2.38G/9.45G [00:32<01:36, 73.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  25%|██▌       | 2.39G/9.45G [00:32<01:38, 72.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  25%|██▌       | 2.40G/9.45G [00:32<01:34, 74.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  26%|██▌       | 2.41G/9.45G [00:33<01:35, 73.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  26%|██▌       | 2.42G/9.45G [00:33<01:30, 77.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  26%|██▌       | 2.43G/9.45G [00:33<01:36, 72.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  26%|██▌       | 2.44G/9.45G [00:33<01:51, 62.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  26%|██▌       | 2.45G/9.45G [00:33<01:42, 68.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  26%|██▌       | 2.46G/9.45G [00:33<01:36, 72.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  26%|██▌       | 2.47G/9.45G [00:34<02:07, 54.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  26%|██▋       | 2.49G/9.45G [00:34<01:53, 61.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  26%|██▋       | 2.50G/9.45G [00:34<01:43, 67.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  27%|██▋       | 2.51G/9.45G [00:34<01:39, 69.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  27%|██▋       | 2.52G/9.45G [00:34<01:38, 70.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  27%|██▋       | 2.53G/9.45G [00:34<01:40, 68.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  27%|██▋       | 2.54G/9.45G [00:35<01:34, 73.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  27%|██▋       | 2.55G/9.45G [00:35<01:31, 75.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  27%|██▋       | 2.56G/9.45G [00:35<01:27, 78.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  27%|██▋       | 2.57G/9.45G [00:35<01:30, 76.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  27%|██▋       | 2.58G/9.45G [00:35<01:27, 78.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  27%|██▋       | 2.59G/9.45G [00:35<01:36, 71.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  28%|██▊       | 2.60G/9.45G [00:35<01:51, 61.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  28%|██▊       | 2.61G/9.45G [00:36<01:44, 65.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  28%|██▊       | 2.62G/9.45G [00:36<01:38, 69.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  28%|██▊       | 2.63G/9.45G [00:36<01:48, 63.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  28%|██▊       | 2.64G/9.45G [00:36<01:41, 67.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  28%|██▊       | 2.65G/9.45G [00:36<01:36, 70.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  28%|██▊       | 2.66G/9.45G [00:36<01:39, 68.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  28%|██▊       | 2.67G/9.45G [00:36<01:31, 74.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  28%|██▊       | 2.68G/9.45G [00:37<01:29, 75.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  29%|██▊       | 2.69G/9.45G [00:37<01:26, 78.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  29%|██▊       | 2.71G/9.45G [00:37<01:25, 78.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  29%|██▊       | 2.72G/9.45G [00:37<01:24, 79.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  29%|██▉       | 2.73G/9.45G [00:37<01:40, 66.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  29%|██▉       | 2.74G/9.45G [00:37<01:46, 62.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  29%|██▉       | 2.75G/9.45G [00:37<01:37, 68.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  29%|██▉       | 2.76G/9.45G [00:38<01:30, 73.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  29%|██▉       | 2.77G/9.45G [00:38<01:39, 67.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  29%|██▉       | 2.78G/9.45G [00:38<01:49, 60.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  30%|██▉       | 2.79G/9.45G [00:38<01:37, 68.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  30%|██▉       | 2.80G/9.45G [00:38<01:32, 71.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  30%|██▉       | 2.81G/9.45G [00:38<01:37, 68.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  30%|██▉       | 2.82G/9.45G [00:39<01:35, 69.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  30%|██▉       | 2.83G/9.45G [00:39<01:29, 74.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  30%|███       | 2.84G/9.45G [00:39<01:30, 72.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  30%|███       | 2.85G/9.45G [00:39<01:37, 67.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  30%|███       | 2.86G/9.45G [00:39<01:32, 71.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  30%|███       | 2.87G/9.45G [00:39<01:29, 73.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  31%|███       | 2.88G/9.45G [00:39<01:27, 75.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  31%|███       | 2.89G/9.45G [00:40<01:23, 78.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  31%|███       | 2.90G/9.45G [00:40<01:22, 79.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  31%|███       | 2.92G/9.45G [00:40<01:23, 77.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  31%|███       | 2.93G/9.45G [00:40<01:30, 71.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  31%|███       | 2.94G/9.45G [00:40<01:25, 75.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  31%|███       | 2.95G/9.45G [00:40<01:23, 77.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  31%|███▏      | 2.96G/9.45G [00:40<01:25, 76.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  31%|███▏      | 2.97G/9.45G [00:41<01:51, 58.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  32%|███▏      | 2.99G/9.45G [00:41<01:27, 73.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  32%|███▏      | 3.00G/9.45G [00:41<01:43, 62.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  32%|███▏      | 3.01G/9.45G [00:41<01:39, 64.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  32%|███▏      | 3.02G/9.45G [00:41<01:48, 59.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  32%|███▏      | 3.03G/9.45G [00:42<01:46, 60.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  32%|███▏      | 3.04G/9.45G [00:42<01:36, 66.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  32%|███▏      | 3.05G/9.45G [00:42<01:30, 70.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  32%|███▏      | 3.06G/9.45G [00:42<01:31, 70.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  33%|███▎      | 3.07G/9.45G [00:42<01:24, 75.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  33%|███▎      | 3.08G/9.45G [00:42<01:33, 68.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  33%|███▎      | 3.09G/9.45G [00:42<01:27, 72.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  33%|███▎      | 3.10G/9.45G [00:43<01:30, 70.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  33%|███▎      | 3.11G/9.45G [00:43<01:26, 73.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  33%|███▎      | 3.12G/9.45G [00:43<01:33, 67.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  33%|███▎      | 3.15G/9.45G [00:43<01:15, 83.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  33%|███▎      | 3.16G/9.45G [00:43<01:18, 79.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  34%|███▎      | 3.17G/9.45G [00:43<01:17, 80.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  34%|███▎      | 3.18G/9.45G [00:44<01:28, 70.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  34%|███▎      | 3.19G/9.45G [00:44<01:25, 73.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  34%|███▍      | 3.20G/9.45G [00:44<01:38, 63.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  34%|███▍      | 3.21G/9.45G [00:44<01:28, 70.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  34%|███▍      | 3.22G/9.45G [00:44<01:23, 74.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  34%|███▍      | 3.23G/9.45G [00:44<01:20, 76.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  34%|███▍      | 3.24G/9.45G [00:44<01:18, 79.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  34%|███▍      | 3.25G/9.45G [00:45<01:25, 72.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  35%|███▍      | 3.26G/9.45G [00:45<01:20, 76.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  35%|███▍      | 3.27G/9.45G [00:45<01:20, 76.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  35%|███▍      | 3.28G/9.45G [00:45<01:18, 78.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  35%|███▍      | 3.29G/9.45G [00:45<01:29, 68.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  35%|███▍      | 3.30G/9.45G [00:45<01:23, 73.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  35%|███▌      | 3.31G/9.45G [00:45<01:22, 74.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  35%|███▌      | 3.32G/9.45G [00:46<01:21, 75.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  35%|███▌      | 3.33G/9.45G [00:46<01:22, 73.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  35%|███▌      | 3.34G/9.45G [00:46<01:24, 72.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  36%|███▌      | 3.36G/9.45G [00:46<01:29, 68.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  36%|███▌      | 3.37G/9.45G [00:46<01:34, 64.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  36%|███▌      | 3.38G/9.45G [00:46<01:27, 69.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  36%|███▌      | 3.39G/9.45G [00:46<01:23, 72.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  36%|███▌      | 3.40G/9.45G [00:47<01:26, 70.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  36%|███▌      | 3.41G/9.45G [00:47<01:27, 68.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  36%|███▌      | 3.42G/9.45G [00:47<01:27, 68.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  36%|███▋      | 3.43G/9.45G [00:47<01:24, 70.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  36%|███▋      | 3.44G/9.45G [00:47<01:23, 72.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  37%|███▋      | 3.45G/9.45G [00:47<01:25, 70.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  37%|███▋      | 3.46G/9.45G [00:47<01:22, 72.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  37%|███▋      | 3.47G/9.45G [00:48<01:23, 71.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  37%|███▋      | 3.48G/9.45G [00:48<01:25, 70.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  37%|███▋      | 3.49G/9.45G [00:48<01:21, 73.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  37%|███▋      | 3.50G/9.45G [00:48<01:18, 76.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  37%|███▋      | 3.51G/9.45G [00:48<01:18, 75.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  37%|███▋      | 3.52G/9.45G [00:48<01:16, 77.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  37%|███▋      | 3.53G/9.45G [00:48<01:18, 75.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  38%|███▊      | 3.54G/9.45G [00:49<01:19, 74.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  38%|███▊      | 3.55G/9.45G [00:49<01:17, 76.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  38%|███▊      | 3.57G/9.45G [00:49<01:16, 77.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  38%|███▊      | 3.58G/9.45G [00:49<01:19, 74.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  38%|███▊      | 3.59G/9.45G [00:49<01:20, 72.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  38%|███▊      | 3.60G/9.45G [00:49<01:18, 74.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  38%|███▊      | 3.61G/9.45G [00:49<01:17, 75.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  38%|███▊      | 3.62G/9.45G [00:50<01:15, 77.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  38%|███▊      | 3.63G/9.45G [00:50<01:25, 68.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  39%|███▊      | 3.64G/9.45G [00:50<01:30, 63.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  39%|███▊      | 3.65G/9.45G [00:50<01:26, 67.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  39%|███▊      | 3.66G/9.45G [00:50<01:22, 70.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  39%|███▉      | 3.67G/9.45G [00:50<01:21, 71.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  39%|███▉      | 3.68G/9.45G [00:50<01:18, 73.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  39%|███▉      | 3.69G/9.45G [00:51<01:19, 72.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  39%|███▉      | 3.70G/9.45G [00:51<01:38, 58.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  39%|███▉      | 3.72G/9.45G [00:51<01:20, 71.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  40%|███▉      | 3.73G/9.45G [00:51<01:22, 69.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  40%|███▉      | 3.74G/9.45G [00:51<01:19, 71.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  40%|███▉      | 3.75G/9.45G [00:52<01:17, 73.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  40%|███▉      | 3.76G/9.45G [00:52<01:16, 74.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  40%|███▉      | 3.77G/9.45G [00:52<01:20, 70.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  40%|████      | 3.79G/9.45G [00:52<01:18, 72.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  40%|████      | 3.80G/9.45G [00:52<01:14, 76.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  40%|████      | 3.81G/9.45G [00:52<01:36, 58.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  40%|████      | 3.82G/9.45G [00:53<01:27, 64.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  41%|████      | 3.83G/9.45G [00:53<01:20, 69.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  41%|████      | 3.84G/9.45G [00:53<01:22, 67.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  41%|████      | 3.85G/9.45G [00:53<01:16, 72.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  41%|████      | 3.86G/9.45G [00:53<01:27, 64.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  41%|████      | 3.87G/9.45G [00:53<01:24, 66.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  41%|████      | 3.88G/9.45G [00:53<01:18, 70.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  41%|████      | 3.89G/9.45G [00:54<01:16, 73.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  41%|████▏     | 3.90G/9.45G [00:54<01:11, 77.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  41%|████▏     | 3.91G/9.45G [00:54<01:12, 76.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  42%|████▏     | 3.92G/9.45G [00:54<01:15, 72.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  42%|████▏     | 3.93G/9.45G [00:54<01:15, 73.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  42%|████▏     | 3.94G/9.45G [00:54<01:16, 71.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  42%|████▏     | 3.95G/9.45G [00:54<01:12, 75.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  42%|████▏     | 3.96G/9.45G [00:55<01:19, 69.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  42%|████▏     | 3.97G/9.45G [00:55<01:14, 73.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  42%|████▏     | 3.98G/9.45G [00:55<01:13, 74.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  42%|████▏     | 4.00G/9.45G [00:55<01:13, 73.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  42%|████▏     | 4.01G/9.45G [00:55<01:12, 75.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  42%|████▏     | 4.02G/9.45G [00:55<01:09, 77.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  43%|████▎     | 4.03G/9.45G [00:55<01:07, 79.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  43%|████▎     | 4.04G/9.45G [00:55<01:05, 82.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  43%|████▎     | 4.05G/9.45G [00:56<01:05, 82.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  43%|████▎     | 4.06G/9.45G [00:56<01:06, 81.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  43%|████▎     | 4.07G/9.45G [00:56<01:06, 81.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  43%|████▎     | 4.08G/9.45G [00:56<01:13, 73.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  43%|████▎     | 4.09G/9.45G [00:56<01:11, 75.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  43%|████▎     | 4.10G/9.45G [00:56<01:10, 75.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  43%|████▎     | 4.11G/9.45G [00:56<01:09, 76.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  44%|████▎     | 4.12G/9.45G [00:57<01:08, 78.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  44%|████▎     | 4.13G/9.45G [00:57<01:10, 75.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  44%|████▍     | 4.14G/9.45G [00:57<01:11, 74.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  44%|████▍     | 4.15G/9.45G [00:57<01:08, 77.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  44%|████▍     | 4.16G/9.45G [00:57<01:14, 71.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  44%|████▍     | 4.17G/9.45G [00:57<01:16, 68.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  44%|████▍     | 4.18G/9.45G [00:57<01:13, 71.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  44%|████▍     | 4.19G/9.45G [00:58<01:09, 75.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  44%|████▍     | 4.20G/9.45G [00:58<01:05, 79.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  45%|████▍     | 4.22G/9.45G [00:58<01:08, 76.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  45%|████▍     | 4.23G/9.45G [00:58<01:11, 72.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  45%|████▍     | 4.24G/9.45G [00:58<01:07, 76.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  45%|████▍     | 4.25G/9.45G [00:58<01:06, 78.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  45%|████▌     | 4.26G/9.45G [00:58<01:05, 79.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  45%|████▌     | 4.27G/9.45G [00:58<01:05, 79.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  45%|████▌     | 4.28G/9.45G [00:59<01:08, 75.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  45%|████▌     | 4.29G/9.45G [00:59<01:06, 77.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  45%|████▌     | 4.30G/9.45G [00:59<01:04, 80.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  46%|████▌     | 4.31G/9.45G [00:59<01:03, 81.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  46%|████▌     | 4.32G/9.45G [00:59<01:05, 78.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  46%|████▌     | 4.33G/9.45G [00:59<01:03, 81.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  46%|████▌     | 4.34G/9.45G [00:59<01:16, 66.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  46%|████▌     | 4.35G/9.45G [01:00<01:14, 68.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  46%|████▌     | 4.36G/9.45G [01:00<01:09, 73.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  46%|████▋     | 4.37G/9.45G [01:00<01:13, 69.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  46%|████▋     | 4.38G/9.45G [01:00<01:13, 69.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  46%|████▋     | 4.39G/9.45G [01:00<01:12, 69.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  47%|████▋     | 4.40G/9.45G [01:00<01:12, 69.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  47%|████▋     | 4.41G/9.45G [01:01<01:13, 68.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  47%|████▋     | 4.42G/9.45G [01:01<01:08, 73.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  47%|████▋     | 4.44G/9.45G [01:01<01:05, 76.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  47%|████▋     | 4.45G/9.45G [01:01<01:33, 53.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  47%|████▋     | 4.46G/9.45G [01:01<01:35, 52.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  47%|████▋     | 4.47G/9.45G [01:01<01:27, 56.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  47%|████▋     | 4.48G/9.45G [01:02<01:18, 63.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  47%|████▋     | 4.49G/9.45G [01:02<01:12, 68.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  48%|████▊     | 4.50G/9.45G [01:02<01:08, 72.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  48%|████▊     | 4.51G/9.45G [01:02<01:08, 72.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  48%|████▊     | 4.52G/9.45G [01:02<01:12, 67.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  48%|████▊     | 4.53G/9.45G [01:02<01:17, 63.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  48%|████▊     | 4.54G/9.45G [01:02<01:11, 68.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  48%|████▊     | 4.55G/9.45G [01:03<01:12, 67.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  48%|████▊     | 4.56G/9.45G [01:03<01:12, 67.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  48%|████▊     | 4.57G/9.45G [01:03<01:06, 72.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  48%|████▊     | 4.58G/9.45G [01:03<01:06, 73.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  49%|████▊     | 4.59G/9.45G [01:03<01:06, 73.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  49%|████▊     | 4.60G/9.45G [01:03<01:05, 73.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  49%|████▉     | 4.61G/9.45G [01:03<01:03, 76.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  49%|████▉     | 4.62G/9.45G [01:04<01:06, 72.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  49%|████▉     | 4.63G/9.45G [01:04<01:09, 69.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  49%|████▉     | 4.65G/9.45G [01:04<01:06, 72.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  49%|████▉     | 4.66G/9.45G [01:04<01:05, 73.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  49%|████▉     | 4.67G/9.45G [01:04<01:02, 76.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  49%|████▉     | 4.68G/9.45G [01:04<01:02, 76.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  50%|████▉     | 4.69G/9.45G [01:04<01:00, 78.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  50%|████▉     | 4.70G/9.45G [01:05<00:59, 80.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  50%|████▉     | 4.71G/9.45G [01:05<00:57, 82.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  50%|████▉     | 4.72G/9.45G [01:05<00:59, 79.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  50%|█████     | 4.73G/9.45G [01:05<01:01, 77.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  50%|█████     | 4.74G/9.45G [01:05<01:25, 55.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  50%|█████     | 4.75G/9.45G [01:05<01:21, 57.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  50%|█████     | 4.76G/9.45G [01:06<01:14, 62.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  50%|█████     | 4.77G/9.45G [01:06<01:13, 63.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  51%|█████     | 4.78G/9.45G [01:06<01:09, 66.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  51%|█████     | 4.79G/9.45G [01:06<01:05, 70.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  51%|█████     | 4.80G/9.45G [01:06<01:06, 70.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  51%|█████     | 4.81G/9.45G [01:06<01:01, 75.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  51%|█████     | 4.82G/9.45G [01:06<01:07, 69.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  51%|█████     | 4.83G/9.45G [01:07<01:06, 69.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  51%|█████▏    | 4.84G/9.45G [01:07<01:02, 73.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  51%|█████▏    | 4.85G/9.45G [01:07<00:59, 77.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  51%|█████▏    | 4.87G/9.45G [01:07<00:59, 76.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  52%|█████▏    | 4.88G/9.45G [01:07<00:59, 77.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  52%|█████▏    | 4.89G/9.45G [01:07<00:58, 77.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  52%|█████▏    | 4.90G/9.45G [01:07<00:56, 80.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  52%|█████▏    | 4.91G/9.45G [01:08<00:55, 81.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  52%|█████▏    | 4.92G/9.45G [01:08<00:54, 83.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  52%|█████▏    | 4.93G/9.45G [01:08<00:55, 81.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  52%|█████▏    | 4.94G/9.45G [01:08<00:58, 77.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  52%|█████▏    | 4.95G/9.45G [01:08<00:57, 77.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  52%|█████▏    | 4.96G/9.45G [01:08<01:10, 63.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  53%|█████▎    | 4.97G/9.45G [01:08<01:03, 70.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  53%|█████▎    | 4.98G/9.45G [01:09<01:05, 68.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  53%|█████▎    | 4.99G/9.45G [01:09<01:03, 69.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  53%|█████▎    | 5.00G/9.45G [01:09<01:00, 74.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  53%|█████▎    | 5.01G/9.45G [01:09<01:16, 58.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  53%|█████▎    | 5.02G/9.45G [01:09<01:09, 63.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  53%|█████▎    | 5.03G/9.45G [01:09<01:12, 60.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  53%|█████▎    | 5.04G/9.45G [01:10<01:09, 63.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  53%|█████▎    | 5.05G/9.45G [01:10<01:07, 65.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  54%|█████▎    | 5.06G/9.45G [01:10<01:10, 61.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  54%|█████▎    | 5.08G/9.45G [01:10<01:06, 65.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  54%|█████▍    | 5.09G/9.45G [01:10<01:09, 63.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  54%|█████▍    | 5.10G/9.45G [01:10<01:05, 66.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  54%|█████▍    | 5.11G/9.45G [01:10<01:02, 69.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  54%|█████▍    | 5.12G/9.45G [01:11<00:59, 72.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  54%|█████▍    | 5.13G/9.45G [01:11<00:55, 77.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  54%|█████▍    | 5.14G/9.45G [01:11<00:54, 79.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  54%|█████▍    | 5.15G/9.45G [01:11<00:55, 78.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  55%|█████▍    | 5.16G/9.45G [01:11<00:56, 76.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  55%|█████▍    | 5.17G/9.45G [01:11<01:08, 62.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  55%|█████▍    | 5.19G/9.45G [01:12<00:59, 71.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  55%|█████▌    | 5.20G/9.45G [01:12<00:59, 71.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  55%|█████▌    | 5.21G/9.45G [01:12<00:58, 72.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  55%|█████▌    | 5.22G/9.45G [01:12<00:59, 70.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  55%|█████▌    | 5.23G/9.45G [01:12<00:59, 71.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  55%|█████▌    | 5.24G/9.45G [01:12<00:59, 71.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  56%|█████▌    | 5.25G/9.45G [01:12<00:56, 74.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  56%|█████▌    | 5.26G/9.45G [01:13<00:53, 78.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  56%|█████▌    | 5.27G/9.45G [01:13<00:55, 74.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  56%|█████▌    | 5.28G/9.45G [01:13<00:52, 78.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  56%|█████▌    | 5.30G/9.45G [01:13<00:59, 70.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  56%|█████▌    | 5.31G/9.45G [01:13<00:57, 72.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  56%|█████▋    | 5.32G/9.45G [01:13<01:00, 68.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  56%|█████▋    | 5.33G/9.45G [01:14<00:58, 70.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  56%|█████▋    | 5.34G/9.45G [01:14<00:56, 72.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  57%|█████▋    | 5.35G/9.45G [01:14<00:53, 76.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  57%|█████▋    | 5.36G/9.45G [01:14<00:58, 70.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  57%|█████▋    | 5.37G/9.45G [01:14<00:55, 73.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  57%|█████▋    | 5.38G/9.45G [01:14<00:55, 73.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  57%|█████▋    | 5.39G/9.45G [01:14<00:53, 76.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  57%|█████▋    | 5.40G/9.45G [01:14<00:50, 79.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  57%|█████▋    | 5.41G/9.45G [01:15<00:49, 80.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  57%|█████▋    | 5.42G/9.45G [01:15<00:49, 82.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  57%|█████▋    | 5.43G/9.45G [01:15<00:49, 81.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  58%|█████▊    | 5.44G/9.45G [01:15<01:12, 55.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  58%|█████▊    | 5.45G/9.45G [01:15<01:10, 56.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  58%|█████▊    | 5.46G/9.45G [01:16<01:09, 57.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  58%|█████▊    | 5.47G/9.45G [01:16<01:03, 62.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  58%|█████▊    | 5.48G/9.45G [01:16<00:58, 67.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  58%|█████▊    | 5.49G/9.45G [01:16<00:55, 71.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  58%|█████▊    | 5.51G/9.45G [01:16<00:52, 75.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  58%|█████▊    | 5.52G/9.45G [01:16<00:49, 79.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  58%|█████▊    | 5.53G/9.45G [01:16<00:48, 80.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  59%|█████▊    | 5.54G/9.45G [01:16<00:52, 74.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  59%|█████▊    | 5.55G/9.45G [01:17<00:50, 77.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  59%|█████▉    | 5.56G/9.45G [01:17<00:49, 78.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  59%|█████▉    | 5.57G/9.45G [01:17<00:51, 75.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  59%|█████▉    | 5.58G/9.45G [01:17<00:50, 76.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  59%|█████▉    | 5.59G/9.45G [01:17<00:57, 67.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  59%|█████▉    | 5.60G/9.45G [01:17<00:56, 68.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  59%|█████▉    | 5.61G/9.45G [01:17<00:51, 74.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  59%|█████▉    | 5.62G/9.45G [01:18<00:51, 74.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  60%|█████▉    | 5.63G/9.45G [01:18<00:48, 78.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  60%|█████▉    | 5.64G/9.45G [01:18<00:47, 80.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  60%|█████▉    | 5.65G/9.45G [01:18<00:46, 82.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  60%|█████▉    | 5.66G/9.45G [01:18<00:48, 78.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  60%|██████    | 5.67G/9.45G [01:18<00:46, 81.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  60%|██████    | 5.68G/9.45G [01:18<00:44, 84.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  60%|██████    | 5.69G/9.45G [01:18<00:48, 77.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  60%|██████    | 5.70G/9.45G [01:19<00:48, 77.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  60%|██████    | 5.71G/9.45G [01:19<00:46, 80.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  61%|██████    | 5.73G/9.45G [01:19<00:45, 81.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  61%|██████    | 5.74G/9.45G [01:19<00:44, 84.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  61%|██████    | 5.75G/9.45G [01:19<00:45, 82.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  61%|██████    | 5.76G/9.45G [01:19<00:44, 82.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  61%|██████    | 5.77G/9.45G [01:19<00:46, 78.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  61%|██████    | 5.78G/9.45G [01:20<00:46, 79.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  61%|██████▏   | 5.79G/9.45G [01:20<00:46, 78.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  61%|██████▏   | 5.80G/9.45G [01:20<00:45, 81.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  61%|██████▏   | 5.81G/9.45G [01:20<00:51, 70.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  62%|██████▏   | 5.82G/9.45G [01:20<00:48, 74.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  62%|██████▏   | 5.83G/9.45G [01:20<00:49, 73.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  62%|██████▏   | 5.84G/9.45G [01:20<00:51, 70.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  62%|██████▏   | 5.85G/9.45G [01:21<00:49, 72.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  62%|██████▏   | 5.86G/9.45G [01:21<00:48, 73.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  62%|██████▏   | 5.87G/9.45G [01:21<00:46, 77.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  62%|██████▏   | 5.88G/9.45G [01:21<00:48, 74.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  62%|██████▏   | 5.89G/9.45G [01:21<00:53, 66.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  63%|██████▎   | 5.91G/9.45G [01:21<00:45, 78.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  63%|██████▎   | 5.92G/9.45G [01:21<00:45, 77.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  63%|██████▎   | 5.93G/9.45G [01:22<00:45, 77.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  63%|██████▎   | 5.95G/9.45G [01:22<00:48, 72.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  63%|██████▎   | 5.96G/9.45G [01:22<00:46, 74.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  63%|██████▎   | 5.97G/9.45G [01:22<00:44, 77.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  63%|██████▎   | 5.98G/9.45G [01:22<00:42, 81.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  63%|██████▎   | 5.99G/9.45G [01:22<00:41, 84.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  63%|██████▎   | 6.00G/9.45G [01:22<00:39, 86.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  64%|██████▎   | 6.01G/9.45G [01:23<00:40, 85.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  64%|██████▎   | 6.02G/9.45G [01:23<00:39, 86.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  64%|██████▍   | 6.03G/9.45G [01:23<00:42, 80.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  64%|██████▍   | 6.04G/9.45G [01:23<00:42, 79.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  64%|██████▍   | 6.05G/9.45G [01:23<00:41, 82.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  64%|██████▍   | 6.06G/9.45G [01:23<00:42, 78.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  64%|██████▍   | 6.07G/9.45G [01:23<00:44, 75.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  64%|██████▍   | 6.08G/9.45G [01:23<00:44, 76.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  64%|██████▍   | 6.09G/9.45G [01:24<00:47, 71.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  65%|██████▍   | 6.10G/9.45G [01:24<00:50, 66.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  65%|██████▍   | 6.11G/9.45G [01:24<00:47, 70.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  65%|██████▍   | 6.12G/9.45G [01:24<00:46, 72.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  65%|██████▍   | 6.13G/9.45G [01:24<00:43, 75.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  65%|██████▌   | 6.14G/9.45G [01:24<00:44, 74.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  65%|██████▌   | 6.16G/9.45G [01:24<00:43, 76.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  65%|██████▌   | 6.17G/9.45G [01:25<00:42, 77.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  65%|██████▌   | 6.18G/9.45G [01:25<00:49, 66.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  65%|██████▌   | 6.19G/9.45G [01:25<00:50, 65.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  66%|██████▌   | 6.20G/9.45G [01:25<00:48, 67.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  66%|██████▌   | 6.21G/9.45G [01:25<00:50, 63.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  66%|██████▌   | 6.22G/9.45G [01:25<00:47, 68.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  66%|██████▌   | 6.23G/9.45G [01:26<00:49, 64.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  66%|██████▌   | 6.24G/9.45G [01:26<00:47, 67.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  66%|██████▌   | 6.25G/9.45G [01:26<00:44, 72.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  66%|██████▌   | 6.26G/9.45G [01:26<00:41, 76.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  66%|██████▋   | 6.27G/9.45G [01:26<00:39, 80.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  66%|██████▋   | 6.28G/9.45G [01:26<00:39, 80.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  67%|██████▋   | 6.29G/9.45G [01:26<00:40, 77.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  67%|██████▋   | 6.30G/9.45G [01:27<00:40, 77.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  67%|██████▋   | 6.31G/9.45G [01:27<00:40, 77.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  67%|██████▋   | 6.32G/9.45G [01:27<00:38, 81.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  67%|██████▋   | 6.33G/9.45G [01:27<00:40, 77.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  67%|██████▋   | 6.34G/9.45G [01:27<00:40, 76.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  67%|██████▋   | 6.35G/9.45G [01:27<00:40, 77.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  67%|██████▋   | 6.36G/9.45G [01:27<00:40, 75.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  67%|██████▋   | 6.38G/9.45G [01:27<00:41, 73.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  68%|██████▊   | 6.39G/9.45G [01:28<00:45, 67.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  68%|██████▊   | 6.40G/9.45G [01:28<00:43, 69.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  68%|██████▊   | 6.41G/9.45G [01:28<00:45, 66.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  68%|██████▊   | 6.42G/9.45G [01:28<00:44, 68.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  68%|██████▊   | 6.43G/9.45G [01:28<00:43, 69.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  68%|██████▊   | 6.44G/9.45G [01:28<00:46, 64.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  68%|██████▊   | 6.45G/9.45G [01:29<00:56, 53.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  68%|██████▊   | 6.46G/9.45G [01:29<00:52, 57.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  68%|██████▊   | 6.47G/9.45G [01:29<00:51, 57.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  69%|██████▊   | 6.48G/9.45G [01:29<00:55, 53.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  69%|██████▊   | 6.49G/9.45G [01:29<00:50, 58.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  69%|██████▉   | 6.50G/9.45G [01:30<00:46, 63.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  69%|██████▉   | 6.51G/9.45G [01:30<00:47, 61.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  69%|██████▉   | 6.52G/9.45G [01:30<00:46, 62.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  69%|██████▉   | 6.53G/9.45G [01:30<00:42, 68.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  69%|██████▉   | 6.54G/9.45G [01:30<00:42, 68.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  69%|██████▉   | 6.55G/9.45G [01:30<00:39, 73.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  69%|██████▉   | 6.56G/9.45G [01:30<00:37, 76.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  70%|██████▉   | 6.57G/9.45G [01:31<00:35, 80.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  70%|██████▉   | 6.59G/9.45G [01:31<00:35, 81.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  70%|██████▉   | 6.60G/9.45G [01:31<00:35, 80.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  70%|██████▉   | 6.61G/9.45G [01:31<00:34, 83.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  70%|███████   | 6.62G/9.45G [01:31<00:33, 84.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  70%|███████   | 6.63G/9.45G [01:31<00:35, 80.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  70%|███████   | 6.64G/9.45G [01:31<00:34, 81.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  70%|███████   | 6.65G/9.45G [01:32<00:49, 56.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  71%|███████   | 6.67G/9.45G [01:32<00:38, 73.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  71%|███████   | 6.68G/9.45G [01:32<00:36, 76.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  71%|███████   | 6.69G/9.45G [01:32<00:36, 75.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  71%|███████   | 6.70G/9.45G [01:32<00:34, 78.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  71%|███████   | 6.71G/9.45G [01:32<00:35, 76.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  71%|███████   | 6.72G/9.45G [01:32<00:36, 75.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  71%|███████   | 6.73G/9.45G [01:33<00:35, 76.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  71%|███████▏  | 6.74G/9.45G [01:33<00:36, 74.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  71%|███████▏  | 6.75G/9.45G [01:33<00:35, 75.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  72%|███████▏  | 6.76G/9.45G [01:33<00:38, 69.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  72%|███████▏  | 6.77G/9.45G [01:33<00:36, 74.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  72%|███████▏  | 6.78G/9.45G [01:33<00:35, 74.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  72%|███████▏  | 6.79G/9.45G [01:34<00:36, 72.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  72%|███████▏  | 6.81G/9.45G [01:34<00:46, 57.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  72%|███████▏  | 6.82G/9.45G [01:34<00:42, 62.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  72%|███████▏  | 6.83G/9.45G [01:34<00:39, 66.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  72%|███████▏  | 6.84G/9.45G [01:34<00:36, 70.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  72%|███████▏  | 6.85G/9.45G [01:34<00:36, 72.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  73%|███████▎  | 6.86G/9.45G [01:34<00:34, 76.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  73%|███████▎  | 6.87G/9.45G [01:35<00:35, 72.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  73%|███████▎  | 6.88G/9.45G [01:35<00:37, 68.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  73%|███████▎  | 6.89G/9.45G [01:35<00:34, 73.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  73%|███████▎  | 6.90G/9.45G [01:35<00:36, 69.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  73%|███████▎  | 6.91G/9.45G [01:35<00:35, 71.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  73%|███████▎  | 6.92G/9.45G [01:35<00:36, 69.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  73%|███████▎  | 6.93G/9.45G [01:36<00:41, 61.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  73%|███████▎  | 6.94G/9.45G [01:36<00:38, 65.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  74%|███████▎  | 6.95G/9.45G [01:36<00:35, 70.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  74%|███████▎  | 6.96G/9.45G [01:36<00:34, 71.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  74%|███████▍  | 6.97G/9.45G [01:36<00:36, 68.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  74%|███████▍  | 6.98G/9.45G [01:36<00:34, 71.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  74%|███████▍  | 6.99G/9.45G [01:36<00:32, 75.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  74%|███████▍  | 7.00G/9.45G [01:37<00:31, 77.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  74%|███████▍  | 7.01G/9.45G [01:37<00:29, 81.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  74%|███████▍  | 7.03G/9.45G [01:37<00:34, 71.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  74%|███████▍  | 7.04G/9.45G [01:37<00:33, 71.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  75%|███████▍  | 7.05G/9.45G [01:37<00:37, 64.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  75%|███████▍  | 7.06G/9.45G [01:37<00:37, 63.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  75%|███████▍  | 7.07G/9.45G [01:37<00:34, 69.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  75%|███████▍  | 7.08G/9.45G [01:38<00:33, 71.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  75%|███████▌  | 7.09G/9.45G [01:38<00:31, 74.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  75%|███████▌  | 7.10G/9.45G [01:38<00:30, 76.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  75%|███████▌  | 7.11G/9.45G [01:38<00:30, 77.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  75%|███████▌  | 7.12G/9.45G [01:38<00:30, 76.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  75%|███████▌  | 7.13G/9.45G [01:38<00:30, 74.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  76%|███████▌  | 7.14G/9.45G [01:38<00:30, 75.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  76%|███████▌  | 7.15G/9.45G [01:39<00:32, 71.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  76%|███████▌  | 7.16G/9.45G [01:39<00:31, 72.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  76%|███████▌  | 7.17G/9.45G [01:39<00:31, 72.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  76%|███████▌  | 7.18G/9.45G [01:39<00:30, 75.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  76%|███████▌  | 7.19G/9.45G [01:39<00:30, 73.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  76%|███████▌  | 7.20G/9.45G [01:39<00:31, 72.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  76%|███████▋  | 7.21G/9.45G [01:39<00:30, 72.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  76%|███████▋  | 7.22G/9.45G [01:40<00:30, 73.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  77%|███████▋  | 7.24G/9.45G [01:40<00:31, 70.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  77%|███████▋  | 7.25G/9.45G [01:40<00:31, 69.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  77%|███████▋  | 7.26G/9.45G [01:40<00:29, 74.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  77%|███████▋  | 7.27G/9.45G [01:40<00:28, 76.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  77%|███████▋  | 7.28G/9.45G [01:40<00:28, 75.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  77%|███████▋  | 7.29G/9.45G [01:40<00:27, 77.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  77%|███████▋  | 7.30G/9.45G [01:41<00:30, 69.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  77%|███████▋  | 7.31G/9.45G [01:41<00:29, 72.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  77%|███████▋  | 7.32G/9.45G [01:41<00:31, 67.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  78%|███████▊  | 7.33G/9.45G [01:41<00:32, 64.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  78%|███████▊  | 7.34G/9.45G [01:41<00:33, 63.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  78%|███████▊  | 7.35G/9.45G [01:41<00:33, 61.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  78%|███████▊  | 7.36G/9.45G [01:42<00:30, 67.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  78%|███████▊  | 7.37G/9.45G [01:42<00:40, 51.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  78%|███████▊  | 7.39G/9.45G [01:42<00:27, 75.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  78%|███████▊  | 7.40G/9.45G [01:42<00:26, 76.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  78%|███████▊  | 7.41G/9.45G [01:42<00:26, 76.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  79%|███████▊  | 7.42G/9.45G [01:42<00:29, 69.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  79%|███████▊  | 7.43G/9.45G [01:43<00:27, 72.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  79%|███████▉  | 7.44G/9.45G [01:43<00:26, 74.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  79%|███████▉  | 7.46G/9.45G [01:43<00:25, 77.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  79%|███████▉  | 7.47G/9.45G [01:43<00:24, 80.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  79%|███████▉  | 7.48G/9.45G [01:43<00:24, 80.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  79%|███████▉  | 7.49G/9.45G [01:43<00:28, 68.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  79%|███████▉  | 7.50G/9.45G [01:43<00:26, 72.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  79%|███████▉  | 7.51G/9.45G [01:44<00:26, 73.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  80%|███████▉  | 7.52G/9.45G [01:44<00:24, 78.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  80%|███████▉  | 7.53G/9.45G [01:44<00:25, 76.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  80%|███████▉  | 7.54G/9.45G [01:44<00:27, 69.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  80%|███████▉  | 7.55G/9.45G [01:44<00:29, 64.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  80%|████████  | 7.56G/9.45G [01:44<00:28, 66.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  80%|████████  | 7.57G/9.45G [01:44<00:26, 71.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  80%|████████  | 7.58G/9.45G [01:45<00:26, 71.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  80%|████████  | 7.59G/9.45G [01:45<00:25, 73.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  80%|████████  | 7.60G/9.45G [01:45<00:26, 69.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  81%|████████  | 7.61G/9.45G [01:45<00:38, 47.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  81%|████████  | 7.62G/9.45G [01:45<00:34, 53.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  81%|████████  | 7.63G/9.45G [01:46<00:33, 54.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  81%|████████  | 7.64G/9.45G [01:46<00:30, 58.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  81%|████████  | 7.65G/9.45G [01:46<00:27, 65.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  81%|████████  | 7.67G/9.45G [01:46<00:25, 69.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  81%|████████  | 7.68G/9.45G [01:46<00:25, 70.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  81%|████████▏ | 7.69G/9.45G [01:46<00:24, 71.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  81%|████████▏ | 7.70G/9.45G [01:46<00:24, 71.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  82%|████████▏ | 7.71G/9.45G [01:47<00:23, 74.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  82%|████████▏ | 7.72G/9.45G [01:47<00:27, 62.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  82%|████████▏ | 7.73G/9.45G [01:47<00:29, 58.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  82%|████████▏ | 7.74G/9.45G [01:47<00:26, 64.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  82%|████████▏ | 7.75G/9.45G [01:47<00:25, 67.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  82%|████████▏ | 7.76G/9.45G [01:47<00:25, 66.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  82%|████████▏ | 7.77G/9.45G [01:48<00:23, 70.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  82%|████████▏ | 7.78G/9.45G [01:48<00:26, 63.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  82%|████████▏ | 7.79G/9.45G [01:48<00:24, 69.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  83%|████████▎ | 7.80G/9.45G [01:48<00:22, 72.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  83%|████████▎ | 7.81G/9.45G [01:48<00:21, 76.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  83%|████████▎ | 7.82G/9.45G [01:48<00:25, 63.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  83%|████████▎ | 7.83G/9.45G [01:48<00:23, 68.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  83%|████████▎ | 7.84G/9.45G [01:49<00:23, 69.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  83%|████████▎ | 7.85G/9.45G [01:49<00:22, 70.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  83%|████████▎ | 7.86G/9.45G [01:49<00:21, 73.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  83%|████████▎ | 7.87G/9.45G [01:49<00:20, 75.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  83%|████████▎ | 7.89G/9.45G [01:49<00:21, 71.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  84%|████████▎ | 7.90G/9.45G [01:49<00:23, 66.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  84%|████████▎ | 7.91G/9.45G [01:50<00:22, 69.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  84%|████████▍ | 7.92G/9.45G [01:50<00:22, 66.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  84%|████████▍ | 7.93G/9.45G [01:50<00:22, 69.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  84%|████████▍ | 7.94G/9.45G [01:50<00:21, 72.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  84%|████████▍ | 7.95G/9.45G [01:50<00:22, 68.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  84%|████████▍ | 7.96G/9.45G [01:50<00:20, 72.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  84%|████████▍ | 7.97G/9.45G [01:50<00:19, 74.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  84%|████████▍ | 7.98G/9.45G [01:51<00:20, 70.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  85%|████████▍ | 7.99G/9.45G [01:51<00:22, 64.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  85%|████████▍ | 8.00G/9.45G [01:51<00:21, 67.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  85%|████████▍ | 8.01G/9.45G [01:51<00:20, 70.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  85%|████████▍ | 8.02G/9.45G [01:51<00:21, 66.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  85%|████████▍ | 8.03G/9.45G [01:51<00:19, 71.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  85%|████████▌ | 8.04G/9.45G [01:51<00:18, 75.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  85%|████████▌ | 8.05G/9.45G [01:52<00:20, 69.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  85%|████████▌ | 8.06G/9.45G [01:52<00:19, 70.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  85%|████████▌ | 8.07G/9.45G [01:52<00:19, 69.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  86%|████████▌ | 8.08G/9.45G [01:52<00:22, 59.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  86%|████████▌ | 8.10G/9.45G [01:52<00:19, 68.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  86%|████████▌ | 8.11G/9.45G [01:52<00:19, 68.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  86%|████████▌ | 8.12G/9.45G [01:53<00:19, 70.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  86%|████████▌ | 8.13G/9.45G [01:53<00:18, 73.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  86%|████████▌ | 8.14G/9.45G [01:53<00:17, 74.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  86%|████████▌ | 8.15G/9.45G [01:53<00:17, 74.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  86%|████████▋ | 8.16G/9.45G [01:53<00:18, 68.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  86%|████████▋ | 8.17G/9.45G [01:53<00:18, 68.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  87%|████████▋ | 8.18G/9.45G [01:53<00:18, 69.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  87%|████████▋ | 8.19G/9.45G [01:54<00:17, 74.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  87%|████████▋ | 8.20G/9.45G [01:54<00:17, 72.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  87%|████████▋ | 8.21G/9.45G [01:54<00:16, 75.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  87%|████████▋ | 8.22G/9.45G [01:54<00:15, 77.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  87%|████████▋ | 8.23G/9.45G [01:54<00:15, 76.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  87%|████████▋ | 8.24G/9.45G [01:54<00:15, 80.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  87%|████████▋ | 8.25G/9.45G [01:54<00:16, 71.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  87%|████████▋ | 8.26G/9.45G [01:55<00:17, 68.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  88%|████████▊ | 8.27G/9.45G [01:55<00:17, 69.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  88%|████████▊ | 8.28G/9.45G [01:55<00:16, 72.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  88%|████████▊ | 8.29G/9.45G [01:55<00:16, 70.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  88%|████████▊ | 8.30G/9.45G [01:55<00:18, 62.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  88%|████████▊ | 8.32G/9.45G [01:55<00:19, 59.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  88%|████████▊ | 8.33G/9.45G [01:56<00:20, 56.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  88%|████████▊ | 8.34G/9.45G [01:56<00:17, 64.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  88%|████████▊ | 8.35G/9.45G [01:56<00:15, 69.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  88%|████████▊ | 8.36G/9.45G [01:56<00:17, 63.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  89%|████████▊ | 8.38G/9.45G [01:56<00:13, 78.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  89%|████████▉ | 8.39G/9.45G [01:56<00:13, 78.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  89%|████████▉ | 8.40G/9.45G [01:57<00:13, 78.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  89%|████████▉ | 8.41G/9.45G [01:57<00:14, 69.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  89%|████████▉ | 8.42G/9.45G [01:57<00:15, 68.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  89%|████████▉ | 8.43G/9.45G [01:57<00:14, 68.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  89%|████████▉ | 8.44G/9.45G [01:57<00:15, 64.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  89%|████████▉ | 8.45G/9.45G [01:57<00:16, 59.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  90%|████████▉ | 8.46G/9.45G [01:58<00:15, 65.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  90%|████████▉ | 8.47G/9.45G [01:58<00:14, 67.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  90%|████████▉ | 8.48G/9.45G [01:58<00:16, 57.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  90%|████████▉ | 8.49G/9.45G [01:58<00:15, 62.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  90%|████████▉ | 8.50G/9.45G [01:58<00:13, 67.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  90%|█████████ | 8.51G/9.45G [01:58<00:15, 62.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  90%|█████████ | 8.52G/9.45G [01:59<00:14, 63.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  90%|█████████ | 8.54G/9.45G [01:59<00:17, 53.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  90%|█████████ | 8.55G/9.45G [01:59<00:16, 55.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  91%|█████████ | 8.56G/9.45G [01:59<00:14, 59.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  91%|█████████ | 8.57G/9.45G [01:59<00:13, 63.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  91%|█████████ | 8.58G/9.45G [01:59<00:12, 67.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  91%|█████████ | 8.59G/9.45G [02:00<00:12, 71.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  91%|█████████ | 8.60G/9.45G [02:00<00:11, 75.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  91%|█████████ | 8.61G/9.45G [02:00<00:12, 67.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  91%|█████████ | 8.62G/9.45G [02:00<00:12, 68.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  91%|█████████▏| 8.63G/9.45G [02:00<00:12, 67.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  91%|█████████▏| 8.64G/9.45G [02:00<00:14, 57.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  92%|█████████▏| 8.65G/9.45G [02:01<00:13, 57.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  92%|█████████▏| 8.66G/9.45G [02:01<00:12, 64.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  92%|█████████▏| 8.67G/9.45G [02:01<00:13, 59.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  92%|█████████▏| 8.68G/9.45G [02:01<00:11, 66.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  92%|█████████▏| 8.69G/9.45G [02:01<00:12, 60.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  92%|█████████▏| 8.70G/9.45G [02:01<00:11, 66.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  92%|█████████▏| 8.71G/9.45G [02:02<00:12, 61.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  92%|█████████▏| 8.72G/9.45G [02:02<00:11, 65.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  92%|█████████▏| 8.73G/9.45G [02:02<00:10, 67.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  93%|█████████▎| 8.75G/9.45G [02:02<00:09, 71.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  93%|█████████▎| 8.76G/9.45G [02:02<00:09, 74.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  93%|█████████▎| 8.77G/9.45G [02:02<00:10, 68.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  93%|█████████▎| 8.78G/9.45G [02:02<00:09, 69.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  93%|█████████▎| 8.79G/9.45G [02:03<00:09, 66.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  93%|█████████▎| 8.80G/9.45G [02:03<00:09, 70.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  93%|█████████▎| 8.81G/9.45G [02:03<00:08, 72.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  93%|█████████▎| 8.82G/9.45G [02:03<00:09, 67.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  93%|█████████▎| 8.83G/9.45G [02:03<00:08, 71.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  94%|█████████▎| 8.84G/9.45G [02:03<00:08, 71.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  94%|█████████▎| 8.85G/9.45G [02:03<00:08, 72.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  94%|█████████▍| 8.86G/9.45G [02:04<00:07, 73.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  94%|█████████▍| 8.87G/9.45G [02:04<00:07, 73.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  94%|█████████▍| 8.88G/9.45G [02:04<00:08, 66.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  94%|█████████▍| 8.89G/9.45G [02:04<00:08, 67.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  94%|█████████▍| 8.90G/9.45G [02:04<00:07, 73.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  94%|█████████▍| 8.91G/9.45G [02:04<00:07, 71.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  94%|█████████▍| 8.92G/9.45G [02:05<00:08, 61.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  95%|█████████▍| 8.93G/9.45G [02:05<00:08, 62.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  95%|█████████▍| 8.94G/9.45G [02:05<00:07, 67.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  95%|█████████▍| 8.95G/9.45G [02:05<00:08, 58.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  95%|█████████▍| 8.97G/9.45G [02:05<00:07, 65.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  95%|█████████▍| 8.98G/9.45G [02:05<00:07, 65.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  95%|█████████▌| 8.99G/9.45G [02:05<00:06, 69.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  95%|█████████▌| 9.00G/9.45G [02:06<00:05, 76.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  95%|█████████▌| 9.01G/9.45G [02:06<00:06, 72.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  95%|█████████▌| 9.02G/9.45G [02:06<00:06, 62.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  96%|█████████▌| 9.03G/9.45G [02:06<00:06, 64.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  96%|█████████▌| 9.04G/9.45G [02:06<00:06, 67.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  96%|█████████▌| 9.05G/9.45G [02:06<00:05, 70.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  96%|█████████▌| 9.06G/9.45G [02:07<00:05, 73.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  96%|█████████▌| 9.07G/9.45G [02:07<00:05, 72.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  96%|█████████▌| 9.08G/9.45G [02:07<00:04, 75.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  96%|█████████▌| 9.09G/9.45G [02:07<00:05, 70.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  96%|█████████▋| 9.10G/9.45G [02:07<00:04, 72.5MB/s][A
Downloading (…)l-00001-of-00002.bin:  96%|█████████▋| 9.11G/9.45G [02:07<00:05, 65.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  97%|█████████▋| 9.12G/9.45G [02:08<00:05, 60.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  97%|█████████▋| 9.13G/9.45G [02:08<00:04, 64.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  97%|█████████▋| 9.14G/9.45G [02:08<00:04, 64.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  97%|█████████▋| 9.15G/9.45G [02:08<00:04, 68.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  97%|█████████▋| 9.16G/9.45G [02:08<00:04, 69.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  97%|█████████▋| 9.18G/9.45G [02:08<00:04, 68.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  97%|█████████▋| 9.19G/9.45G [02:08<00:03, 70.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  97%|█████████▋| 9.20G/9.45G [02:09<00:03, 74.2MB/s][A
Downloading (…)l-00001-of-00002.bin:  97%|█████████▋| 9.21G/9.45G [02:09<00:03, 77.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  98%|█████████▊| 9.22G/9.45G [02:09<00:02, 78.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  98%|█████████▊| 9.23G/9.45G [02:09<00:02, 76.4MB/s][A
Downloading (…)l-00001-of-00002.bin:  98%|█████████▊| 9.24G/9.45G [02:09<00:03, 61.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  98%|█████████▊| 9.25G/9.45G [02:09<00:03, 63.7MB/s][A
Downloading (…)l-00001-of-00002.bin:  98%|█████████▊| 9.26G/9.45G [02:10<00:03, 55.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  98%|█████████▊| 9.27G/9.45G [02:10<00:02, 62.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  98%|█████████▊| 9.28G/9.45G [02:10<00:02, 62.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  98%|█████████▊| 9.29G/9.45G [02:10<00:02, 70.6MB/s][A
Downloading (…)l-00001-of-00002.bin:  98%|█████████▊| 9.30G/9.45G [02:10<00:02, 74.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  99%|█████████▊| 9.31G/9.45G [02:10<00:01, 73.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  99%|█████████▊| 9.32G/9.45G [02:10<00:01, 75.3MB/s][A
Downloading (…)l-00001-of-00002.bin:  99%|█████████▉| 9.33G/9.45G [02:10<00:01, 74.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  99%|█████████▉| 9.34G/9.45G [02:11<00:01, 66.0MB/s][A
Downloading (…)l-00001-of-00002.bin:  99%|█████████▉| 9.35G/9.45G [02:11<00:01, 65.9MB/s][A
Downloading (…)l-00001-of-00002.bin:  99%|█████████▉| 9.36G/9.45G [02:11<00:01, 67.8MB/s][A
Downloading (…)l-00001-of-00002.bin:  99%|█████████▉| 9.37G/9.45G [02:11<00:01, 63.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  99%|█████████▉| 9.38G/9.45G [02:11<00:00, 68.1MB/s][A
Downloading (…)l-00001-of-00002.bin:  99%|█████████▉| 9.40G/9.45G [02:11<00:00, 71.8MB/s][A
Downloading (…)l-00001-of-00002.bin: 100%|█████████▉| 9.41G/9.45G [02:12<00:00, 74.7MB/s][A
Downloading (…)l-00001-of-00002.bin: 100%|█████████▉| 9.42G/9.45G [02:12<00:00, 72.6MB/s][A
Downloading (…)l-00001-of-00002.bin: 100%|█████████▉| 9.43G/9.45G [02:12<00:00, 75.3MB/s][A
Downloading (…)l-00001-of-00002.bin: 100%|█████████▉| 9.44G/9.45G [02:12<00:00, 73.4MB/s][A
Downloading (…)l-00001-of-00002.bin: 100%|█████████▉| 9.45G/9.45G [02:12<00:00, 70.8MB/s][ADownloading (…)l-00001-of-00002.bin: 100%|██████████| 9.45G/9.45G [02:12<00:00, 71.1MB/s]
Downloading shards:  50%|█████     | 1/2 [02:15<02:15, 135.73s/it]
Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/1.95G [00:00<?, ?B/s][A
Downloading (…)l-00002-of-00002.bin:   1%|          | 10.5M/1.95G [00:00<00:40, 48.3MB/s][A
Downloading (…)l-00002-of-00002.bin:   1%|          | 21.0M/1.95G [00:00<00:29, 66.2MB/s][A
Downloading (…)l-00002-of-00002.bin:   2%|▏         | 31.5M/1.95G [00:00<00:29, 66.1MB/s][A
Downloading (…)l-00002-of-00002.bin:   2%|▏         | 41.9M/1.95G [00:00<00:30, 62.9MB/s][A
Downloading (…)l-00002-of-00002.bin:   3%|▎         | 52.4M/1.95G [00:00<00:28, 65.6MB/s][A
Downloading (…)l-00002-of-00002.bin:   3%|▎         | 62.9M/1.95G [00:00<00:28, 67.3MB/s][A
Downloading (…)l-00002-of-00002.bin:   4%|▍         | 73.4M/1.95G [00:01<00:25, 73.1MB/s][A
Downloading (…)l-00002-of-00002.bin:   4%|▍         | 83.9M/1.95G [00:01<00:25, 74.0MB/s][A
Downloading (…)l-00002-of-00002.bin:   5%|▍         | 94.4M/1.95G [00:01<00:23, 78.7MB/s][A
Downloading (…)l-00002-of-00002.bin:   5%|▌         | 105M/1.95G [00:01<00:22, 82.6MB/s] [A
Downloading (…)l-00002-of-00002.bin:   6%|▌         | 115M/1.95G [00:01<00:23, 78.4MB/s][A
Downloading (…)l-00002-of-00002.bin:   6%|▋         | 126M/1.95G [00:01<00:24, 75.6MB/s][A
Downloading (…)l-00002-of-00002.bin:   7%|▋         | 136M/1.95G [00:01<00:23, 76.6MB/s][A
Downloading (…)l-00002-of-00002.bin:   8%|▊         | 147M/1.95G [00:02<00:23, 78.0MB/s][A
Downloading (…)l-00002-of-00002.bin:   8%|▊         | 157M/1.95G [00:02<00:23, 74.7MB/s][A
Downloading (…)l-00002-of-00002.bin:   9%|▊         | 168M/1.95G [00:02<00:22, 79.1MB/s][A
Downloading (…)l-00002-of-00002.bin:   9%|▉         | 178M/1.95G [00:02<00:21, 82.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  10%|▉         | 189M/1.95G [00:02<00:20, 84.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  10%|█         | 199M/1.95G [00:02<00:20, 86.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  11%|█         | 210M/1.95G [00:02<00:20, 86.1MB/s][A
Downloading (…)l-00002-of-00002.bin:  11%|█▏        | 220M/1.95G [00:02<00:20, 84.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  12%|█▏        | 231M/1.95G [00:02<00:19, 86.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  12%|█▏        | 241M/1.95G [00:03<00:20, 83.7MB/s][A
Downloading (…)l-00002-of-00002.bin:  13%|█▎        | 252M/1.95G [00:03<00:20, 82.0MB/s][A
Downloading (…)l-00002-of-00002.bin:  13%|█▎        | 262M/1.95G [00:03<00:21, 79.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  14%|█▍        | 273M/1.95G [00:03<00:20, 81.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  15%|█▍        | 283M/1.95G [00:03<00:23, 70.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  15%|█▌        | 294M/1.95G [00:03<00:22, 74.0MB/s][A
Downloading (…)l-00002-of-00002.bin:  16%|█▌        | 304M/1.95G [00:03<00:22, 73.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  16%|█▌        | 315M/1.95G [00:04<00:22, 73.7MB/s][A
Downloading (…)l-00002-of-00002.bin:  17%|█▋        | 325M/1.95G [00:04<00:22, 73.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  17%|█▋        | 336M/1.95G [00:04<00:22, 72.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  18%|█▊        | 346M/1.95G [00:04<00:21, 75.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  18%|█▊        | 357M/1.95G [00:04<00:20, 79.0MB/s][A
Downloading (…)l-00002-of-00002.bin:  19%|█▉        | 367M/1.95G [00:04<00:20, 78.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  19%|█▉        | 377M/1.95G [00:04<00:20, 77.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  20%|█▉        | 388M/1.95G [00:05<00:19, 80.7MB/s][A
Downloading (…)l-00002-of-00002.bin:  20%|██        | 398M/1.95G [00:05<00:19, 80.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  21%|██        | 409M/1.95G [00:05<00:19, 77.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  22%|██▏       | 419M/1.95G [00:05<00:19, 76.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  22%|██▏       | 430M/1.95G [00:05<00:19, 78.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  23%|██▎       | 440M/1.95G [00:05<00:19, 76.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  23%|██▎       | 451M/1.95G [00:05<00:18, 79.0MB/s][A
Downloading (…)l-00002-of-00002.bin:  24%|██▎       | 461M/1.95G [00:06<00:18, 78.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  24%|██▍       | 472M/1.95G [00:06<00:19, 77.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  25%|██▍       | 482M/1.95G [00:06<00:18, 81.1MB/s][A
Downloading (…)l-00002-of-00002.bin:  25%|██▌       | 493M/1.95G [00:06<00:17, 83.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  26%|██▌       | 503M/1.95G [00:06<00:17, 85.0MB/s][A
Downloading (…)l-00002-of-00002.bin:  26%|██▋       | 514M/1.95G [00:06<00:17, 81.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  27%|██▋       | 524M/1.95G [00:06<00:17, 83.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  27%|██▋       | 535M/1.95G [00:06<00:17, 79.0MB/s][A
Downloading (…)l-00002-of-00002.bin:  28%|██▊       | 545M/1.95G [00:07<00:17, 82.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  29%|██▊       | 556M/1.95G [00:07<00:17, 81.0MB/s][A
Downloading (…)l-00002-of-00002.bin:  29%|██▉       | 566M/1.95G [00:07<00:16, 82.0MB/s][A
Downloading (…)l-00002-of-00002.bin:  30%|██▉       | 577M/1.95G [00:07<00:16, 83.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  30%|███       | 587M/1.95G [00:07<00:16, 82.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  31%|███       | 598M/1.95G [00:07<00:22, 61.0MB/s][A
Downloading (…)l-00002-of-00002.bin:  31%|███       | 608M/1.95G [00:07<00:20, 66.0MB/s][A
Downloading (…)l-00002-of-00002.bin:  32%|███▏      | 619M/1.95G [00:08<00:18, 70.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  32%|███▏      | 629M/1.95G [00:08<00:17, 76.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  33%|███▎      | 640M/1.95G [00:08<00:21, 61.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  33%|███▎      | 650M/1.95G [00:08<00:18, 69.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  34%|███▍      | 661M/1.95G [00:08<00:18, 70.1MB/s][A
Downloading (…)l-00002-of-00002.bin:  34%|███▍      | 671M/1.95G [00:08<00:17, 73.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  35%|███▍      | 682M/1.95G [00:08<00:16, 75.1MB/s][A
Downloading (…)l-00002-of-00002.bin:  35%|███▌      | 692M/1.95G [00:09<00:17, 72.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  36%|███▌      | 703M/1.95G [00:09<00:16, 77.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  37%|███▋      | 713M/1.95G [00:09<00:15, 80.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  37%|███▋      | 724M/1.95G [00:09<00:14, 83.0MB/s][A
Downloading (…)l-00002-of-00002.bin:  38%|███▊      | 734M/1.95G [00:09<00:14, 84.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  38%|███▊      | 744M/1.95G [00:09<00:13, 86.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  39%|███▊      | 755M/1.95G [00:09<00:13, 85.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  39%|███▉      | 765M/1.95G [00:09<00:15, 78.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  40%|███▉      | 776M/1.95G [00:10<00:24, 47.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  41%|████      | 797M/1.95G [00:10<00:19, 59.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  41%|████▏     | 807M/1.95G [00:10<00:17, 63.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  42%|████▏     | 818M/1.95G [00:10<00:17, 65.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  42%|████▏     | 828M/1.95G [00:11<00:16, 67.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  43%|████▎     | 839M/1.95G [00:11<00:15, 73.7MB/s][A
Downloading (…)l-00002-of-00002.bin:  44%|████▎     | 849M/1.95G [00:11<00:14, 76.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  44%|████▍     | 860M/1.95G [00:11<00:13, 81.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  45%|████▍     | 870M/1.95G [00:11<00:13, 79.7MB/s][A
Downloading (…)l-00002-of-00002.bin:  45%|████▌     | 881M/1.95G [00:11<00:13, 81.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  46%|████▌     | 891M/1.95G [00:11<00:12, 81.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  46%|████▋     | 902M/1.95G [00:11<00:13, 77.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  47%|████▋     | 912M/1.95G [00:12<00:13, 78.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  47%|████▋     | 923M/1.95G [00:12<00:12, 81.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  48%|████▊     | 933M/1.95G [00:12<00:12, 82.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  48%|████▊     | 944M/1.95G [00:12<00:12, 83.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  49%|████▉     | 954M/1.95G [00:12<00:12, 81.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  49%|████▉     | 965M/1.95G [00:12<00:11, 84.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  50%|█████     | 975M/1.95G [00:12<00:11, 83.7MB/s][A
Downloading (…)l-00002-of-00002.bin:  51%|█████     | 986M/1.95G [00:13<00:13, 69.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  51%|█████     | 996M/1.95G [00:13<00:13, 68.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  52%|█████▏    | 1.01G/1.95G [00:13<00:13, 67.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  52%|█████▏    | 1.02G/1.95G [00:13<00:12, 74.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  53%|█████▎    | 1.03G/1.95G [00:13<00:12, 72.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  53%|█████▎    | 1.04G/1.95G [00:13<00:13, 69.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  54%|█████▍    | 1.05G/1.95G [00:13<00:12, 74.7MB/s][A
Downloading (…)l-00002-of-00002.bin:  54%|█████▍    | 1.06G/1.95G [00:14<00:14, 62.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  55%|█████▍    | 1.07G/1.95G [00:14<00:13, 67.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  55%|█████▌    | 1.08G/1.95G [00:14<00:12, 69.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  56%|█████▌    | 1.09G/1.95G [00:14<00:14, 60.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  56%|█████▋    | 1.10G/1.95G [00:14<00:13, 62.1MB/s][A
Downloading (…)l-00002-of-00002.bin:  57%|█████▋    | 1.11G/1.95G [00:14<00:13, 61.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  58%|█████▊    | 1.12G/1.95G [00:15<00:12, 65.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  58%|█████▊    | 1.13G/1.95G [00:15<00:11, 70.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  59%|█████▊    | 1.14G/1.95G [00:15<00:10, 74.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  59%|█████▉    | 1.15G/1.95G [00:15<00:10, 79.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  60%|█████▉    | 1.16G/1.95G [00:15<00:09, 81.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  60%|██████    | 1.17G/1.95G [00:15<00:09, 82.1MB/s][A
Downloading (…)l-00002-of-00002.bin:  61%|██████    | 1.18G/1.95G [00:15<00:09, 81.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  61%|██████▏   | 1.20G/1.95G [00:15<00:08, 84.7MB/s][A
Downloading (…)l-00002-of-00002.bin:  62%|██████▏   | 1.21G/1.95G [00:16<00:08, 82.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  62%|██████▏   | 1.22G/1.95G [00:16<00:08, 82.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  63%|██████▎   | 1.23G/1.95G [00:16<00:09, 78.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  63%|██████▎   | 1.24G/1.95G [00:16<00:09, 77.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  64%|██████▍   | 1.25G/1.95G [00:16<00:09, 77.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  65%|██████▍   | 1.26G/1.95G [00:16<00:08, 81.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  65%|██████▌   | 1.27G/1.95G [00:16<00:08, 76.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  66%|██████▌   | 1.28G/1.95G [00:16<00:08, 78.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  66%|██████▌   | 1.29G/1.95G [00:17<00:08, 80.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  67%|██████▋   | 1.30G/1.95G [00:17<00:07, 82.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  67%|██████▋   | 1.31G/1.95G [00:17<00:07, 80.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  68%|██████▊   | 1.32G/1.95G [00:17<00:07, 82.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  68%|██████▊   | 1.33G/1.95G [00:17<00:07, 83.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  69%|██████▉   | 1.34G/1.95G [00:17<00:07, 84.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  69%|██████▉   | 1.35G/1.95G [00:17<00:07, 84.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  70%|██████▉   | 1.36G/1.95G [00:17<00:07, 80.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  70%|███████   | 1.37G/1.95G [00:18<00:07, 81.1MB/s][A
Downloading (…)l-00002-of-00002.bin:  71%|███████   | 1.38G/1.95G [00:18<00:06, 83.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  72%|███████▏  | 1.39G/1.95G [00:18<00:06, 81.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  72%|███████▏  | 1.41G/1.95G [00:18<00:07, 76.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  73%|███████▎  | 1.42G/1.95G [00:18<00:06, 77.7MB/s][A
Downloading (…)l-00002-of-00002.bin:  73%|███████▎  | 1.43G/1.95G [00:18<00:07, 73.0MB/s][A
Downloading (…)l-00002-of-00002.bin:  74%|███████▎  | 1.44G/1.95G [00:18<00:06, 77.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  74%|███████▍  | 1.45G/1.95G [00:19<00:06, 78.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  75%|███████▍  | 1.46G/1.95G [00:19<00:06, 81.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  75%|███████▌  | 1.47G/1.95G [00:19<00:05, 83.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  76%|███████▌  | 1.48G/1.95G [00:19<00:05, 86.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  76%|███████▋  | 1.49G/1.95G [00:19<00:05, 79.0MB/s][A
Downloading (…)l-00002-of-00002.bin:  77%|███████▋  | 1.50G/1.95G [00:19<00:05, 81.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  77%|███████▋  | 1.51G/1.95G [00:19<00:05, 74.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  78%|███████▊  | 1.52G/1.95G [00:19<00:05, 78.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  79%|███████▊  | 1.53G/1.95G [00:20<00:05, 78.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  79%|███████▉  | 1.54G/1.95G [00:20<00:05, 74.1MB/s][A
Downloading (…)l-00002-of-00002.bin:  80%|███████▉  | 1.55G/1.95G [00:20<00:07, 52.7MB/s][A
Downloading (…)l-00002-of-00002.bin:  81%|████████  | 1.57G/1.95G [00:20<00:04, 76.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  81%|████████  | 1.58G/1.95G [00:20<00:04, 73.6MB/s][A
Downloading (…)l-00002-of-00002.bin:  82%|████████▏ | 1.59G/1.95G [00:21<00:04, 71.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  82%|████████▏ | 1.60G/1.95G [00:21<00:04, 74.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  83%|████████▎ | 1.61G/1.95G [00:21<00:04, 77.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  83%|████████▎ | 1.63G/1.95G [00:21<00:04, 80.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  84%|████████▍ | 1.64G/1.95G [00:21<00:04, 72.0MB/s][A
Downloading (…)l-00002-of-00002.bin:  84%|████████▍ | 1.65G/1.95G [00:21<00:04, 75.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  85%|████████▍ | 1.66G/1.95G [00:21<00:03, 76.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  86%|████████▌ | 1.67G/1.95G [00:22<00:03, 73.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  86%|████████▌ | 1.68G/1.95G [00:22<00:03, 77.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  87%|████████▋ | 1.69G/1.95G [00:22<00:03, 79.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  87%|████████▋ | 1.70G/1.95G [00:22<00:03, 82.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  88%|████████▊ | 1.71G/1.95G [00:22<00:02, 84.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  88%|████████▊ | 1.72G/1.95G [00:22<00:02, 83.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  89%|████████▊ | 1.73G/1.95G [00:22<00:02, 84.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  89%|████████▉ | 1.74G/1.95G [00:22<00:02, 85.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  90%|████████▉ | 1.75G/1.95G [00:22<00:02, 86.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  90%|█████████ | 1.76G/1.95G [00:23<00:02, 84.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  91%|█████████ | 1.77G/1.95G [00:23<00:02, 81.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  91%|█████████▏| 1.78G/1.95G [00:23<00:02, 75.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  92%|█████████▏| 1.79G/1.95G [00:23<00:02, 78.1MB/s][A
Downloading (…)l-00002-of-00002.bin:  93%|█████████▎| 1.80G/1.95G [00:23<00:01, 79.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  93%|█████████▎| 1.81G/1.95G [00:23<00:01, 74.5MB/s][A
Downloading (…)l-00002-of-00002.bin:  94%|█████████▎| 1.82G/1.95G [00:23<00:01, 77.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  94%|█████████▍| 1.84G/1.95G [00:24<00:01, 78.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  95%|█████████▍| 1.85G/1.95G [00:24<00:01, 80.8MB/s][A
Downloading (…)l-00002-of-00002.bin:  95%|█████████▌| 1.86G/1.95G [00:24<00:01, 69.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  96%|█████████▌| 1.87G/1.95G [00:24<00:01, 66.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  96%|█████████▋| 1.88G/1.95G [00:24<00:01, 71.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  97%|█████████▋| 1.89G/1.95G [00:24<00:00, 73.9MB/s][A
Downloading (…)l-00002-of-00002.bin:  97%|█████████▋| 1.90G/1.95G [00:24<00:00, 76.2MB/s][A
Downloading (…)l-00002-of-00002.bin:  98%|█████████▊| 1.91G/1.95G [00:25<00:00, 78.3MB/s][A
Downloading (…)l-00002-of-00002.bin:  98%|█████████▊| 1.92G/1.95G [00:25<00:00, 77.4MB/s][A
Downloading (…)l-00002-of-00002.bin:  99%|█████████▉| 1.93G/1.95G [00:25<00:00, 74.3MB/s][A
Downloading (…)l-00002-of-00002.bin: 100%|█████████▉| 1.94G/1.95G [00:25<00:00, 76.2MB/s][A
Downloading (…)l-00002-of-00002.bin: 100%|██████████| 1.95G/1.95G [00:25<00:00, 78.4MB/s][ADownloading (…)l-00002-of-00002.bin: 100%|██████████| 1.95G/1.95G [00:25<00:00, 76.1MB/s]
Downloading shards: 100%|██████████| 2/2 [02:44<00:00, 72.54s/it] Downloading shards: 100%|██████████| 2/2 [02:44<00:00, 82.02s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:20<00:20, 20.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 11.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.65s/it]
Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]Downloading (…)neration_config.json: 100%|██████████| 147/147 [00:00<00:00, 1.55MB/s]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:28<01:54, 28.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:59<01:30, 30.02s/it]Loading checkpoint shards:  60%|██████    | 3/5 [01:31<01:01, 30.92s/it]Loading checkpoint shards:  80%|████████  | 4/5 [02:04<00:31, 31.54s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:23<00:00, 27.24s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:23<00:00, 28.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:30<02:03, 30.99s/it]Loading checkpoint shards:  40%|████      | 2/5 [01:01<01:31, 30.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [01:32<01:01, 30.84s/it]Loading checkpoint shards:  80%|████████  | 4/5 [02:06<00:32, 32.11s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:25<00:00, 27.53s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:25<00:00, 29.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:29<01:59, 29.96s/it]Loading checkpoint shards:  40%|████      | 2/5 [01:02<01:35, 31.73s/it]Loading checkpoint shards:  60%|██████    | 3/5 [01:35<01:04, 32.15s/it]Loading checkpoint shards:  80%|████████  | 4/5 [02:07<00:32, 32.04s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:26<00:00, 27.46s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:26<00:00, 29.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:29<01:58, 29.74s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:59<01:29, 29.98s/it]Loading checkpoint shards:  60%|██████    | 3/5 [01:31<01:01, 30.78s/it]Loading checkpoint shards:  80%|████████  | 4/5 [02:02<00:30, 30.79s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:24<00:00, 27.52s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:24<00:00, 28.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:29<01:57, 29.34s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:59<01:30, 30.04s/it]Loading checkpoint shards:  60%|██████    | 3/5 [01:34<01:03, 32.00s/it]Loading checkpoint shards:  80%|████████  | 4/5 [02:08<00:33, 33.09s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:28<00:00, 28.05s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:28<00:00, 29.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 13, in <module>
    run_experiment.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 37, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 24, in _evaluate_model
    encodings = _generate_encodings(tokenizer, dataset_shard)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiment.py", line 10, in _generate_encodings
    encodings = tokenizer(dataset["question"], padding=True, truncation=True, return_tensors="pt").to(device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2602, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2688, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2879, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 744, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils.py", line 816, in _batch_prepare_for_model
    batch_outputs = self.pad(
                    ^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3018, in pad
    raise ValueError(
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
