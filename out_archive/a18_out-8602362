mkdir: cannot create directory ‘/scratch/general/vast/u1283221/huggingface_cache’: File exists
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:24<01:38, 24.75s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:46<01:09, 23.13s/it]Loading checkpoint shards:  60%|██████    | 3/5 [01:09<00:46, 23.01s/it]Loading checkpoint shards:  80%|████████  | 4/5 [01:32<00:22, 22.91s/it]Loading checkpoint shards: 100%|██████████| 5/5 [01:38<00:00, 16.95s/it]Loading checkpoint shards: 100%|██████████| 5/5 [01:38<00:00, 19.75s/it]
>> Input file: ./data/multiplication/prompt_type_1/aggregate_count_1/concatenate.csv, module: google/flan-t5-xxl
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 11781.75it/s]
Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 274.78it/s]
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 1000 examples [00:00, 61385.75 examples/s]
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:10<18:03, 10.95s/it]  2%|▏         | 2/100 [00:13<10:02,  6.14s/it]  3%|▎         | 3/100 [00:16<07:26,  4.60s/it]  4%|▍         | 4/100 [00:19<06:12,  3.88s/it]  5%|▌         | 5/100 [00:22<05:30,  3.48s/it]  6%|▌         | 6/100 [00:24<05:04,  3.24s/it]  7%|▋         | 7/100 [00:27<04:46,  3.08s/it]  8%|▊         | 8/100 [00:30<04:34,  2.98s/it]  9%|▉         | 9/100 [00:33<04:24,  2.91s/it] 10%|█         | 10/100 [00:35<04:17,  2.86s/it] 11%|█         | 11/100 [00:38<04:00,  2.70s/it] 12%|█▏        | 12/100 [00:40<03:47,  2.59s/it] 13%|█▎        | 13/100 [00:42<03:38,  2.51s/it] 14%|█▍        | 14/100 [00:45<03:31,  2.46s/it] 15%|█▌        | 15/100 [00:47<03:25,  2.42s/it] 16%|█▌        | 16/100 [00:50<03:31,  2.52s/it] 17%|█▋        | 17/100 [00:52<03:24,  2.46s/it] 18%|█▊        | 18/100 [00:54<03:18,  2.42s/it] 19%|█▉        | 19/100 [00:57<03:24,  2.52s/it] 20%|██        | 20/100 [01:00<03:27,  2.59s/it] 21%|██        | 21/100 [01:02<03:18,  2.51s/it] 22%|██▏       | 22/100 [01:05<03:11,  2.46s/it] 23%|██▎       | 23/100 [01:07<03:06,  2.42s/it] 24%|██▍       | 24/100 [01:09<03:01,  2.39s/it] 25%|██▌       | 25/100 [01:12<03:07,  2.50s/it] 26%|██▌       | 26/100 [01:14<03:01,  2.45s/it] 27%|██▋       | 27/100 [01:17<02:56,  2.41s/it] 28%|██▊       | 28/100 [01:19<02:51,  2.39s/it] 29%|██▉       | 29/100 [01:21<02:48,  2.37s/it] 30%|███       | 30/100 [01:24<02:44,  2.36s/it] 31%|███       | 31/100 [01:26<02:41,  2.35s/it] 32%|███▏      | 32/100 [01:28<02:39,  2.34s/it] 33%|███▎      | 33/100 [01:31<02:44,  2.46s/it] 34%|███▍      | 34/100 [01:33<02:39,  2.42s/it] 35%|███▌      | 35/100 [01:36<02:35,  2.39s/it] 36%|███▌      | 36/100 [01:38<02:40,  2.50s/it] 37%|███▋      | 37/100 [01:41<02:34,  2.45s/it] 38%|███▊      | 38/100 [01:43<02:37,  2.54s/it] 39%|███▉      | 39/100 [01:46<02:38,  2.60s/it] 40%|████      | 40/100 [01:49<02:38,  2.65s/it] 41%|████      | 41/100 [01:51<02:30,  2.55s/it] 42%|████▏     | 42/100 [01:54<02:24,  2.48s/it] 43%|████▎     | 43/100 [01:56<02:18,  2.44s/it] 44%|████▍     | 44/100 [01:58<02:14,  2.40s/it] 45%|████▌     | 45/100 [02:01<02:10,  2.38s/it] 46%|████▌     | 46/100 [02:03<02:07,  2.36s/it] 47%|████▋     | 47/100 [02:05<02:04,  2.35s/it] 48%|████▊     | 48/100 [02:08<02:01,  2.35s/it] 49%|████▉     | 49/100 [02:10<01:59,  2.34s/it] 50%|█████     | 50/100 [02:12<01:56,  2.34s/it] 51%|█████     | 51/100 [02:15<01:54,  2.33s/it] 52%|█████▏    | 52/100 [02:17<01:51,  2.33s/it] 53%|█████▎    | 53/100 [02:19<01:49,  2.33s/it] 54%|█████▍    | 54/100 [02:22<01:47,  2.33s/it] 55%|█████▌    | 55/100 [02:24<01:44,  2.33s/it] 56%|█████▌    | 56/100 [02:26<01:42,  2.33s/it] 57%|█████▋    | 57/100 [02:29<01:40,  2.33s/it] 58%|█████▊    | 58/100 [02:31<01:43,  2.46s/it] 59%|█████▉    | 59/100 [02:34<01:44,  2.54s/it] 60%|██████    | 60/100 [02:37<01:44,  2.61s/it] 61%|██████    | 61/100 [02:40<01:43,  2.65s/it] 62%|██████▏   | 62/100 [02:42<01:37,  2.55s/it] 63%|██████▎   | 63/100 [02:45<01:36,  2.61s/it] 64%|██████▍   | 64/100 [02:47<01:35,  2.65s/it] 65%|██████▌   | 65/100 [02:50<01:33,  2.68s/it] 66%|██████▌   | 66/100 [02:53<01:31,  2.70s/it] 67%|██████▋   | 67/100 [02:56<01:29,  2.72s/it] 68%|██████▊   | 68/100 [02:58<01:27,  2.73s/it] 69%|██████▉   | 69/100 [03:01<01:24,  2.74s/it] 70%|███████   | 70/100 [03:04<01:22,  2.74s/it] 71%|███████   | 71/100 [03:06<01:15,  2.62s/it] 72%|███████▏  | 72/100 [03:09<01:14,  2.66s/it] 73%|███████▎  | 73/100 [03:12<01:12,  2.68s/it] 74%|███████▍  | 74/100 [03:14<01:10,  2.70s/it] 75%|███████▌  | 75/100 [03:17<01:07,  2.72s/it] 76%|███████▌  | 76/100 [03:20<01:02,  2.60s/it] 77%|███████▋  | 77/100 [03:22<01:00,  2.65s/it] 78%|███████▊  | 78/100 [03:25<00:58,  2.68s/it] 79%|███████▉  | 79/100 [03:28<00:56,  2.70s/it] 80%|████████  | 80/100 [03:31<00:54,  2.72s/it] 81%|████████  | 81/100 [03:33<00:49,  2.60s/it] 82%|████████▏ | 82/100 [03:35<00:45,  2.52s/it] 83%|████████▎ | 83/100 [03:38<00:44,  2.59s/it] 84%|████████▍ | 84/100 [03:41<00:42,  2.64s/it] 85%|████████▌ | 85/100 [03:43<00:40,  2.67s/it] 86%|████████▌ | 86/100 [03:46<00:37,  2.70s/it] 87%|████████▋ | 87/100 [03:49<00:35,  2.71s/it] 88%|████████▊ | 88/100 [03:52<00:32,  2.73s/it] 89%|████████▉ | 89/100 [03:55<00:30,  2.73s/it] 90%|█████████ | 90/100 [03:57<00:27,  2.74s/it] 91%|█████████ | 91/100 [04:00<00:23,  2.62s/it] 92%|█████████▏| 92/100 [04:02<00:20,  2.53s/it] 93%|█████████▎| 93/100 [04:05<00:18,  2.60s/it] 94%|█████████▍| 94/100 [04:07<00:15,  2.64s/it] 95%|█████████▌| 95/100 [04:10<00:13,  2.67s/it] 96%|█████████▌| 96/100 [04:12<00:10,  2.57s/it] 97%|█████████▋| 97/100 [04:15<00:07,  2.62s/it] 98%|█████████▊| 98/100 [04:18<00:05,  2.66s/it] 99%|█████████▉| 99/100 [04:21<00:02,  2.69s/it]100%|██████████| 100/100 [04:23<00:00,  2.71s/it]100%|██████████| 100/100 [04:23<00:00,  2.64s/it]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 28025.36 examples/s]
Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 154.94ba/s]
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:02<03:55,  2.38s/it]  2%|▏         | 2/100 [00:05<04:14,  2.60s/it]  3%|▎         | 3/100 [00:07<04:19,  2.67s/it]  4%|▍         | 4/100 [00:10<04:19,  2.70s/it]  5%|▌         | 5/100 [00:13<04:18,  2.72s/it]  6%|▌         | 6/100 [00:16<04:16,  2.73s/it]  7%|▋         | 7/100 [00:18<04:14,  2.74s/it]  8%|▊         | 8/100 [00:21<04:12,  2.75s/it]  9%|▉         | 9/100 [00:24<04:10,  2.75s/it] 10%|█         | 10/100 [00:27<04:07,  2.75s/it] 10%|█         | 10/100 [00:33<05:03,  3.38s/it]
Traceback (most recent call last):
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/t5_cte.py", line 18, in <module>
    run_experiments.run_experiments(model, tokenizer, batch_size, input_file, output_folder, experiment_count)
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiments.py", line 38, in run_experiments
    predictions = _evaluate_model(model, tokenizer, dataset, batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiments.py", line 25, in _evaluate_model
    generated_texts = _generate_texts(model, tokenizer, encodings)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/compositional_task_evaluation/run_experiments.py", line 15, in _generate_texts
    generated_ids = model.generate(**encodings, max_new_tokens=20, num_beams=5, do_sample=True)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/generation/utils.py", line 1712, in generate
    return self.beam_sample(
           ^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/generation/utils.py", line 3338, in beam_sample
    outputs = self(
              ^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py", line 1774, in forward
    lm_logits = self.lm_head(sequence_output)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/accelerate/hooks.py", line 160, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/accelerate/hooks.py", line 286, in pre_forward
    set_module_tensor_to_device(
  File "/uufs/chpc.utah.edu/common/home/u1283221/miniconda3/envs/compositional/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 313, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 502.00 MiB (GPU 0; 44.55 GiB total capacity; 43.36 GiB already allocated; 164.25 MiB free; 44.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
